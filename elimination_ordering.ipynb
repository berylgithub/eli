{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "from scipy.io import mmread, mminfo\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Elimination Ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Normalize Stage'''\n",
    "'''preliminaries:\n",
    "- node == vertex (\"vertices\" for plural)\n",
    "- nodes' index start at 0\n",
    "- all graphs and trees are represented in matrix farm\n",
    "- valency is the sum of the edges' weights of a node, i.e. the sum of the row in a corresponding index, in numpy:\n",
    "    np.sum(graph[node_idx])\n",
    "- currently, the matrix is assumed to be symmetric (undirected)\n",
    "- a fill is only calculated during the elimination, not during the algorithm process to get the elimination ordering,\n",
    "and a fill is A[i][j] = 1 iff A[i][k] = A[k][i] = A[j][k] = A[k][j] = 1 then A[i][k] = A[k][i] = A[j][k] = A[k][j] = 0\n",
    "- the diagonal element is always ignored (must be zero'd first if it's nonzero)\n",
    "- non zeros' values doesn't matter (unweighted), it's always binary (0,1)\n",
    "'''\n",
    "'''independent functions:'''\n",
    "\n",
    "#for transforiming tree matrices to ordered list\n",
    "def topological_sort_tree(tree_in):\n",
    "    #look for the \"first\" node, which is the node with no incoming edges:\n",
    "    tree = np.copy(tree_in) #copy the tree so the input wont be affected\n",
    "    size = tree.shape[0]\n",
    "    S = []\n",
    "    for i in range(size):\n",
    "        #need to exclude disconnected nodes by checking row-wise too:\n",
    "        if np.sum(tree[:,i]) == 0:\n",
    "            if np.sum(tree[i]) > 0:\n",
    "                S.append(i)\n",
    "    #print(\"S\",S)\n",
    "    \n",
    "    enque = lambda q, x: q.append(x)\n",
    "    deque = lambda q: q.pop(0)\n",
    "    #kahn's algorithm for topological sort (https://en.wikipedia.org/wiki/Topological_sorting):\n",
    "    #input: tree, first_nodes\n",
    "    L = []\n",
    "    while len(S) > 0:\n",
    "        n = deque(S)\n",
    "        L.append(n)\n",
    "        ms = np.where(tree[n] == 1)[0]    #look for set of destination nodesf rom n (neighbours)\n",
    "        #for each node m with an edge e from n to m:\n",
    "        for m in ms:\n",
    "            tree[n][m] = 0 #remove edge e from the graph\n",
    "            if np.sum(tree[:,m]) == 0: #if m has no other incoming edges then\n",
    "                enque(S, m) #insert m into S\n",
    "    #there should be a final check whether the graph still has some edges, but it isnt necessary for tree cases since trees wont have DAG\n",
    "    return L\n",
    "\n",
    "#Breadth-First-Search traversal algorithm:\n",
    "def BFS(graph, source):\n",
    "    n_init = graph.shape[0]\n",
    "    q = []\n",
    "    enque = lambda q, x: q.append(x)\n",
    "    deque = lambda q: q.pop(0)\n",
    "    visited = np.array([0]*n_init)\n",
    "    distances = np.array([0]*n_init)\n",
    "    visited[source] = 1\n",
    "    enque(q, source)\n",
    "    q_counter = 1 #to keep track how many neighbours enqueued\n",
    "    path = []\n",
    "    while q:\n",
    "        v = deque(q)\n",
    "        q_counter = q_counter - 1\n",
    "        neighbours = np.where(graph[v] == 1)[0] #enque all v's neighbours (gamma(v))\n",
    "        for node_i in neighbours:\n",
    "            if (visited[node_i] == 0) and (node_i not in q):\n",
    "                enque(q, node_i)\n",
    "                visited[node_i] = 1\n",
    "                q_counter += 1\n",
    "        #print(v, neighbours, q, q_counter, depth)\n",
    "        path.append(v)\n",
    "    return path\n",
    "\n",
    "#get ordered list from merge forest\n",
    "def get_ordered_list_merged_vertex(tree, placed_vertex):\n",
    "    '''algorithm for tree-tracing that covers all scenarios:\n",
    "    0. transpose the tree (to get the reverse order), due to the nature of the merge procedure, the leaves will be the roots\n",
    "    1. topological sort to get the root(s)\n",
    "    2. determine the roots by checking the connections between vertices\n",
    "    3. if there are more than one roots:\n",
    "        BFS traverse starting from the placed node to get the ordered lists\n",
    "    else:\n",
    "        just use the list from the topological sort as the ordered list\n",
    "    '''\n",
    "    #print(\"edges:\", np.where(tree.T == 1))\n",
    "    topological_list = topological_sort_tree(tree.T)\n",
    "    #print(\"topological_list\",topological_list)\n",
    "    '''\n",
    "    print(\"topological_list\",topological_list)\n",
    "    print(tree)\n",
    "    print(tree.T)\n",
    "    '''\n",
    "    #check the number of roots and get the corresponding roots:\n",
    "    length = len(topological_list)\n",
    "    roots = [topological_list[0]]\n",
    "    for i_elem in topological_list:\n",
    "        non_root_found = False\n",
    "        for j_elem in topological_list:\n",
    "            if i_elem != j_elem:\n",
    "                if tree.T[i_elem][j_elem] == 0:\n",
    "                    #print(i_elem, j_elem)\n",
    "                    roots.append(j_elem)\n",
    "                else:\n",
    "                    non_root_found = True\n",
    "                    break\n",
    "        if non_root_found:\n",
    "            break\n",
    "    #print(\"roots\",roots)\n",
    "    #if more than one roots, do BFS starting from the placed node, else just use the topological_list:\n",
    "    ordered_list = None\n",
    "    #print(\"ordlist bfs reversed:\",list(reversed(BFS(tree, placed_vertex))))\n",
    "    if len(roots) > 1:\n",
    "        #ordered_list = BFS(tree.T, placed_vertex)\n",
    "        ordered_list = list(reversed(BFS(tree, placed_vertex)))\n",
    "        #print(\"orderedlist bfs\",ordered_list)\n",
    "    else:\n",
    "        ordered_list = topological_list\n",
    "        #print(\"orderedlist\",topological_list)\n",
    "    #print(\"ordered_list\",ordered_list)\n",
    "    return ordered_list\n",
    "\n",
    "#clique checker:\n",
    "def clique_check(graph, vertices_idx):\n",
    "    #get subgraph, by slicing indexes:\n",
    "    subgraph = graph[vertices_idx][:,vertices_idx]\n",
    "    n = subgraph.shape[0]\n",
    "    #check for clique from subgraph:\n",
    "    upper_tri = subgraph[np.triu_indices(n, 1)]\n",
    "    return np.sum(upper_tri) == comb(n, 2)\n",
    "\n",
    "#subset checker:\n",
    "def check_subset(graph, neighbours):\n",
    "    bool_subset = False\n",
    "    j_get = None\n",
    "    for j_node in neighbours:\n",
    "        #probably need to be stopped earlier? instead of taking the last neighbour index\n",
    "        gamma_j = np.where(graph[j_node] == 1)[0]\n",
    "        j_T = np.append(gamma_j, j_node) #j^up_tack = j union gamma(j):= j added to its neighbours\n",
    "        if set(neighbours).issubset(set(j_T)): #gamma(i) \\subset j^up_tack\n",
    "            bool_subset = True\n",
    "            j_get = j_node\n",
    "            break #stop when found\n",
    "    return bool_subset, j_get\n",
    "\n",
    "#more accurate way of checking the total nodes within a graph, since the edge is represented \n",
    "#by the value of A[i][j] cell, e.g if i <-> j is connected, it means A[i][j] = A[j][i] 1, otherwise 0, \n",
    "#so the size of the matrix may not correspond to the total number of nodes\n",
    "def get_total_nodes(graph, row_size):\n",
    "    counter = 0\n",
    "    for i in range(row_size):\n",
    "        if np.sum(graph[i]) > 0:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "'''end'''\n",
    "\n",
    "\n",
    "def initialize(graph):\n",
    "    '''function for data initialization, returns:\n",
    "    - e vector placeholder\n",
    "    - weight vector w\n",
    "    - empty merge forest\n",
    "    - first zero and last zero idxes\n",
    "    - deleted bool array\n",
    "    '''\n",
    "    n = graph.shape[0]\n",
    "    e = np.array([-1]*n) #for now the placeholder is an array of -1\n",
    "    w = np.array([1]*n) #weight vector for merge forest\n",
    "    merge_forest = np.zeros((n,n)) #merge forest for assessment criteria\n",
    "    deleted = np.array([False]*n)\n",
    "    first_zero = 0; last_zero = -1\n",
    "    return e, w, first_zero, last_zero, merge_forest, deleted\n",
    "\n",
    "#normalize stage:\n",
    "def normalize(graph):\n",
    "    global deleted, e, w, first_zero, last_zero, merge_forest\n",
    "    n = n_init = graph.shape[0] #number of nodes\n",
    "    '''e = np.array([-1]*n) #for now the placeholder is an array of -1\n",
    "    w = np.array([1]*n) #weight vector for merge forest\n",
    "    merge_forest = np.zeros((n,n)) #merge forest for assessment criteria'''\n",
    "    modified = np.array([1]*n) #modified = 1, otherwise 0'''\n",
    "\n",
    "\n",
    "    #normalize stage\n",
    "    #for now, cyclic ordering assumption: start from the 1st index to last idx, hence for-loop\n",
    "    #need merge check for every node passed, by w[i] > 1\n",
    "    #print(\"i, n, m, valency, e, summodified, firstzero, lastzero\")\n",
    "    while np.sum(modified) > 0:\n",
    "        #print()\n",
    "        #for i in range(n_init):\n",
    "        for i in range(n_init):\n",
    "            #check if it is already deleted, if yes, skip:\n",
    "            if deleted[i]: #deleted in prev round\n",
    "                modified[i] = 0 #set modified to 0\n",
    "                #print(\"already deleted:\",i)\n",
    "                continue\n",
    "            if np.sum(modified) == 0:\n",
    "                break\n",
    "            #recalculate all of the values:\n",
    "            n = get_total_nodes(graph, n_init) #recalculate n by excluding zero vectored rows (disconnected vertices)\n",
    "            valencies = np.array([np.sum(graph[j]) for j in range(n_init)]) #needs to recalculate the valency for each update due to the graph-change\n",
    "            #print(i,n,m,valency,valencies,e,modified)\n",
    "            mean_valency = np.sum(valencies)/n #get mean valency\n",
    "            max_valency = np.max(valencies) #get max valency\n",
    "            valency = np.sum(graph[i]) #get vertex's valency\n",
    "            m = np.min([mean_valency, np.floor(n**(1/4) + 3)])\n",
    "            #m = np.floor(n**(1/4) + 3) #probably this is the correct interpretiation\n",
    "            #print(\"mean_valency, np.floor(n**(1/4) + 3)\",mean_valency, np.floor(n**(1/4) + 3))\n",
    "            neighbours = np.where(graph[i] == 1)[0] #get the neighbours of i\n",
    "            #print(i,n,m,valency,e,np.sum(modified),first_zero, last_zero)\n",
    "            #print(\"neighbours\",neighbours)\n",
    "            #check all of the conditions based on the valency\n",
    "            if valency == n-1:\n",
    "                ##always check for merge - i.e w[i] > 1\n",
    "                if w[i] > 1:\n",
    "                    ordered_list = get_ordered_list_merged_vertex(merge_forest, i)\n",
    "                    len_e = len(e)\n",
    "                    len_ord_list = len(ordered_list)\n",
    "                    e[len_e + last_zero - len_ord_list + 1 : len_e + last_zero + 1] = ordered_list #lastzero placement\n",
    "                    last_zero -= len_ord_list #decrement last zero by the size of the ordered list \n",
    "                else:\n",
    "                    #add to the last zero and decrement the indexer:\n",
    "                    e[last_zero] = i\n",
    "                    last_zero -= 1\n",
    "                graph[i] = graph[:,i] = 0  #remove from graph by deleting edges\n",
    "                deleted[i] = True\n",
    "                #graph = np.delete(graph, i, 0) #delete from graph -- this should be the proper deletion method, though not sure if it's faster\n",
    "                #graph = np.delete(graph, i, 1)\n",
    "                modified[neighbours] = 1 #set neighbours as modified\n",
    "                #print(\"rule 1\")\n",
    "            elif (valency > np.ceil(n/2)) and (valency == max_valency):\n",
    "                if w[i] > 1:\n",
    "                    ordered_list = get_ordered_list_merged_vertex(merge_forest, i)\n",
    "                    len_e = len(e)\n",
    "                    len_ord_list = len(ordered_list)\n",
    "                    e[len_e + last_zero - len_ord_list + 1 : len_e + last_zero + 1] = ordered_list\n",
    "                    last_zero -= len_ord_list\n",
    "                else:\n",
    "                    e[last_zero] = i\n",
    "                    last_zero -= 1\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                deleted[i] = True\n",
    "                modified[neighbours] = 1\n",
    "                #print(\"rule 2\")\n",
    "            elif valency <= 1:\n",
    "                #e.insert(0, i) #place vertex first\n",
    "                if w[i] > 1:\n",
    "                    ordered_list = get_ordered_list_merged_vertex(merge_forest, i)\n",
    "                    len_e = len(e)\n",
    "                    len_ord_list = len(ordered_list)\n",
    "                    e[first_zero : first_zero + len_ord_list] = ordered_list #insert by firstzero pos\n",
    "                    first_zero += len_ord_list #increment the first zero by the size of the ordered list\n",
    "                else:\n",
    "                    #add to the first zero pos and increment the indexer:\n",
    "                    e[first_zero] = i\n",
    "                    first_zero += 1\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                deleted[i] = True\n",
    "                modified[neighbours] = 1\n",
    "                #print(\"rule 3\")\n",
    "            elif valency == 2:\n",
    "                #e.insert(0, i)\n",
    "                if w[i] > 1:\n",
    "                    ordered_list = get_ordered_list_merged_vertex(merge_forest, i)\n",
    "                    len_e = len(e)\n",
    "                    len_ord_list = len(ordered_list)\n",
    "                    e[first_zero : first_zero + len_ord_list] = ordered_list #insert by firstzero pos\n",
    "                    first_zero += len_ord_list\n",
    "                else:\n",
    "                    #add to the first zero pos and increment the indexer:\n",
    "                    e[first_zero] = i\n",
    "                    first_zero += 1\n",
    "                graph[neighbours[0]][neighbours[1]] = graph[neighbours[1]][neighbours[0]] = 1 #make edge between them -- fill the value of the cell with 1\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                deleted[i] = True\n",
    "                modified[neighbours] = 1\n",
    "                #print(\"rule 4\")\n",
    "            elif (valency <= m) and (clique_check(graph, neighbours)):\n",
    "                #e.insert(0, i)\n",
    "                if w[i] > 1:\n",
    "                    ordered_list = get_ordered_list_merged_vertex(merge_forest, i)\n",
    "                    #print(\"tree[i]\",np.where(merge_forest[i] == 1))\n",
    "                    len_e = len(e)\n",
    "                    len_ord_list = len(ordered_list)\n",
    "                    e[first_zero : first_zero + len_ord_list] = ordered_list #insert by firstzero pos\n",
    "                    first_zero += len_ord_list\n",
    "                    #print(\"place multiple nodes\",ordered_list)\n",
    "                else:\n",
    "                    #add to the first zero pos and increment the indexer:\n",
    "                    #print(\"place one node\")\n",
    "                    e[first_zero] = i\n",
    "                    first_zero += 1\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                deleted[i] = True\n",
    "                modified[neighbours] = 1\n",
    "                #print(\"rule 5\")\n",
    "            elif (valency <= m): \n",
    "                bool_subset, j_node = check_subset(graph, neighbours) #gamma(i) \\subset j^uptack, j \\in gamma(i)\n",
    "                if bool_subset:\n",
    "                    merge_forest[j_node][i] = 1 #merge i into j, add directed edge j->i\n",
    "                    w[j_node] += 1 #increment weight\n",
    "                    graph[i] = graph[:,i] = 0\n",
    "                    deleted[i] = True\n",
    "                    modified[neighbours] = 1\n",
    "                    #print(\"rule 6\")\n",
    "                    #print(neighbours, modified[neighbours])\n",
    "                    #print(\"merged\",i,j_node)\n",
    "            modified[i] = 0 #set vertex as unmodified\n",
    "            #print(\"w,deleted\",w[i],np.where(deleted == True)[0])\n",
    "            #print()\n",
    "    #return e, w, first_zero, last_zero, merge_forest\n",
    "    #return first_zero, last_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S [2, 3]\n",
      "[ 7  9  8 -1 -1 -1 -1 -1  5  6] [3, 1]\n",
      "10 2\n",
      "5 8\n",
      "[ 7  9  8 -1 -1 -1  3  1  5  6]\n"
     ]
    }
   ],
   "source": [
    "'''merge-forest placement test'''\n",
    "dummy_order = np.array([7,9,8,-1,-1,-1,-1,-1,5,6])\n",
    "dummy_placed = 3\n",
    "dum_fz = 3\n",
    "dum_lz = -3\n",
    "\n",
    "#topological sort:\n",
    "t = np.array([[0,0,1,0,0], #0-2,1-3,4-2\n",
    "              [0,0,0,1,0],\n",
    "              [0,0,0,0,0],\n",
    "              [0,0,0,0,0],\n",
    "              [0,0,1,0,0]\n",
    "             ])\n",
    "'''\n",
    "t = np.array([[0,1,0,0],\n",
    "              [0,0,1,0],\n",
    "              [0,0,0,1],\n",
    "              [0,0,0,0]])\n",
    "'''\n",
    "\n",
    "\n",
    "ordered_list = get_ordered_list_merged_vertex(t, dummy_placed)\n",
    "print(dummy_order,ordered_list)\n",
    "#place first:\n",
    "length = len(ordered_list)\n",
    "length_do = len(dummy_order)\n",
    "print(length_do, length)\n",
    "dummy_order[dum_fz : dum_fz + length] = ordered_list #firstzero placement\n",
    "print(length_do + dum_lz - length, length_do + dum_lz + 1) #5,8\n",
    "dummy_order[length_do + dum_lz - length + 1: length_do + dum_lz + 1] = ordered_list #lastzero placement\n",
    "print(dummy_order)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Graphs used for initial assesment:\n",
    "graph is:   \n",
    "     4--6--5\n",
    "     |  | /\n",
    "  3--7--1\n",
    "  |  |  |\n",
    "  8--0--2\n",
    "  \n",
    "graph_1 is a bipartite graph (Nauru graph): https://en.wikipedia.org/wiki/Adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 1 1 1 0]\n",
      " [1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 1 1 0 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]]\n",
      "True\n",
      "i, n, m, valency, valencies, e, modified, firstzero, lastzero\n",
      "\n",
      "0 9 2.6666666666666665 3 [3 4 2 2 2 2 3 4 2] [-1 -1 -1 -1 -1 -1 -1 -1 -1] [1 1 1 1 1 1 1 1 1] 9 0 -1\n",
      "neighbours [2 7 8]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "1 9 2.6666666666666665 4 [3 4 2 2 2 2 3 4 2] [-1 -1 -1 -1 -1 -1 -1 -1 -1] [0 1 1 1 1 1 1 1 1] 8 0 -1\n",
      "neighbours [2 5 6 7]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "2 9 2.6666666666666665 2 [3 4 2 2 2 2 3 4 2] [-1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 1 1 1 1 1 1 1] 7 0 -1\n",
      "neighbours [0 1]\n",
      "rule 4\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2]\n",
      "\n",
      "3 8 2.75 2 [3 4 0 2 2 2 3 4 2] [ 2 -1 -1 -1 -1 -1 -1 -1 -1] [1 1 0 1 1 1 1 1 1] 8 1 -1\n",
      "neighbours [7 8]\n",
      "rule 4\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2 3]\n",
      "\n",
      "4 7 2.857142857142857 2 [3 4 0 0 2 2 3 4 2] [ 2  3 -1 -1 -1 -1 -1 -1 -1] [1 1 0 0 1 1 1 1 1] 7 2 -1\n",
      "neighbours [6 7]\n",
      "rule 4\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2 3 4]\n",
      "\n",
      "5 6 3.0 2 [3 4 0 0 0 2 3 4 2] [ 2  3  4 -1 -1 -1 -1 -1 -1] [1 1 0 0 0 1 1 1 1] 6 3 -1\n",
      "neighbours [1 6]\n",
      "rule 4\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2 3 4 5]\n",
      "\n",
      "6 5 2.8 2 [3 3 0 0 0 0 2 4 2] [ 2  3  4  5 -1 -1 -1 -1 -1] [1 1 0 0 0 0 1 1 1] 5 4 -1\n",
      "neighbours [1 7]\n",
      "rule 4\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2 3 4 5 6]\n",
      "\n",
      "7 4 2.5 3 [3 2 0 0 0 0 0 3 2] [ 2  3  4  5  6 -1 -1 -1 -1] [1 1 0 0 0 0 0 1 1] 4 5 -1\n",
      "neighbours [0 1 8]\n",
      "rule 1\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2 3 4 5 6 7]\n",
      "\n",
      "8 3 1.3333333333333333 1 [2 1 0 0 0 0 0 0 1] [ 2  3  4  5  6 -1 -1 -1  7] [1 1 0 0 0 0 0 0 1] 3 5 -2\n",
      "neighbours [0]\n",
      "rule 3\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [2 3 4 5 6 7 8]\n",
      "\n",
      "\n",
      "0 2 1.0 1 [1 1 0 0 0 0 0 0 0] [ 2  3  4  5  6  8 -1 -1  7] [1 1 0 0 0 0 0 0 0] 2 6 -2\n",
      "neighbours [1]\n",
      "rule 1\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [0 2 3 4 5 6 7 8]\n",
      "\n",
      "1 0 nan 0 [0 0 0 0 0 0 0 0 0] [ 2  3  4  5  6  8 -1  0  7] [0 1 0 0 0 0 0 0 0] 1 6 -3\n",
      "neighbours []\n",
      "rule 3\n",
      "w,deleted [1 1 1 1 1 1 1 1 1] [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "already deleted: 2\n",
      "already deleted: 3\n",
      "already deleted: 4\n",
      "already deleted: 5\n",
      "already deleted: 6\n",
      "already deleted: 7\n",
      "already deleted: 8\n",
      "None\n",
      "e, w, first_zero, last_zero, merge_forest, deleted [2 3 4 5 6 8 1 0 7] [1 1 1 1 1 1 1 1 1] 7 -3 [[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]] [ True  True  True  True  True  True  True  True  True]\n",
      "i, n, m, valency, valencies, e, modified, firstzero, lastzero\n",
      "\n",
      "0 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 24 0 -1\n",
      "neighbours [ 1  5 21]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "1 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 23 0 -1\n",
      "neighbours [ 0  3 15]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "2 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 22 0 -1\n",
      "neighbours [ 3  4 23]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "3 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 21 0 -1\n",
      "neighbours [1 2 9]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "4 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 20 0 -1\n",
      "neighbours [ 2  5 17]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "5 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 19 0 -1\n",
      "neighbours [ 0  4 11]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "6 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 18 0 -1\n",
      "neighbours [ 7 11 19]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "7 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 17 0 -1\n",
      "neighbours [ 6  9 13]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "8 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 16 0 -1\n",
      "neighbours [ 9 10 22]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "9 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 15 0 -1\n",
      "neighbours [3 7 8]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "10 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 14 0 -1\n",
      "neighbours [ 8 11 16]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "11 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1] 13 0 -1\n",
      "neighbours [ 5  6 10]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "12 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1] 12 0 -1\n",
      "neighbours [13 17 18]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "13 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1] 11 0 -1\n",
      "neighbours [ 7 12 15]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "14 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1] 10 0 -1\n",
      "neighbours [15 16 20]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "15 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1] 9 0 -1\n",
      "neighbours [ 1 13 14]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "16 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1] 8 0 -1\n",
      "neighbours [10 14 17]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "17 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1] 7 0 -1\n",
      "neighbours [ 4 12 16]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "18 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1] 6 0 -1\n",
      "neighbours [12 19 23]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "19 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1] 5 0 -1\n",
      "neighbours [ 6 18 21]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "20 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1] 4 0 -1\n",
      "neighbours [14 21 22]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "21 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1] 3 0 -1\n",
      "neighbours [ 0 19 20]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "22 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] 2 0 -1\n",
      "neighbours [ 8 20 23]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "23 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] 1 0 -1\n",
      "neighbours [ 2 18 22]\n",
      "w,deleted [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] []\n",
      "\n",
      "None\n",
      "e, w, first_zero, last_zero, merge_forest, deleted [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 0 -1 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:195: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "'''graphs collection for normalization testing'''\n",
    "#test array/graph from https://people.sc.fsu.edu/~jburkardt/m_src/rcm/rcm.html\n",
    "graph = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "             ])\n",
    "print(graph)\n",
    "\n",
    "#nauru graph\n",
    "graph_1 = np.zeros((24,24))\n",
    "graph_1[0][1] = graph_1[0][5] = graph_1[0][21] = \\\n",
    "graph_1[1][3] = graph_1[1][15] = \\\n",
    "graph_1[2][3] = graph_1[2][4] = graph_1[2][23] = \\\n",
    "graph_1[3][9] = graph_1[4][5] = graph_1[4][17] = \\\n",
    "graph_1[5][11] = graph_1[6][7] = graph_1[6][11] = graph_1[6][19] = \\\n",
    "graph_1[7][9] = graph_1[7][13] = \\\n",
    "graph_1[8][9] = graph_1[8][10] = graph_1[8][22] = \\\n",
    "graph_1[10][11] = graph_1[10][16] = \\\n",
    "graph_1[12][13] = graph_1[12][17] = graph_1[12][18] = \\\n",
    "graph_1[13][15] = graph_1[14][15] = graph_1[14][16] = graph_1[14][20] = \\\n",
    "graph_1[16][17] = graph_1[18][19] = graph_1[18][23] = \\\n",
    "graph_1[19][21] = graph_1[20][21] = graph_1[20][22] = \\\n",
    "graph_1[22][23] = 1\n",
    "graph_1 += graph_1.T\n",
    "print(np.allclose(graph_1, graph_1.T, rtol=1e-05, atol=1e-08))\n",
    "\n",
    "'''testing-ground for normalize stage'''\n",
    "e, w, first_zero, last_zero, merge_forest, deleted = initialize(graph)\n",
    "print(normalize(graph))\n",
    "print(\"e, w, first_zero, last_zero, merge_forest, deleted\",e, w, first_zero, last_zero, merge_forest, deleted)\n",
    "\n",
    "e, w, first_zero, last_zero, merge_forest, deleted = initialize(graph_1)\n",
    "print(normalize(graph_1))\n",
    "print(\"e, w, first_zero, last_zero, merge_forest, deleted\",e, w, first_zero, last_zero, merge_forest, deleted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g2:\n",
      "symm True\n",
      "clique True\n",
      "1^up_tack (True, 1)\n",
      "i, n, m, valency, valencies, e, modified, firstzero, lastzero\n",
      "\n",
      "4.285714285714286 4.0\n",
      "0 7 4.0 3 [3 4 5 6 5 4 3] [-1 -1 -1 -1 -1 -1 -1] [1 1 1 1 1 1 1] 7 0 -1\n",
      "rule 5\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "4.0 4.0\n",
      "1 6 4.0 3 [0 3 4 5 5 4 3] [ 0 -1 -1 -1 -1 -1 -1] [0 1 1 1 1 1 1] 6 1 -1\n",
      "rule 5\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "3.6 4.0\n",
      "2 5 3.6 3 [0 0 3 4 4 4 3] [ 0  1 -1 -1 -1 -1 -1] [0 0 1 1 1 1 1] 5 2 -1\n",
      "rule 5\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "3.0 4.0\n",
      "3 4 3.0 3 [0 0 0 3 3 3 3] [ 0  1  2 -1 -1 -1 -1] [0 0 0 1 1 1 1] 4 3 -1\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "2.0 4.0\n",
      "4 3 2.0 2 [0 0 0 0 2 2 2] [ 0  1  2 -1 -1 -1  3] [0 0 0 0 1 1 1] 3 3 -2\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "1.0 4.0\n",
      "5 2 1.0 1 [0 0 0 0 0 1 1] [ 0  1  2 -1 -1  4  3] [0 0 0 0 0 1 1] 2 3 -3\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "nan 3.0\n",
      "6 0 nan 0 [0 0 0 0 0 0 0] [ 0  1  2 -1  5  4  3] [0 0 0 0 0 0 1] 1 3 -4\n",
      "rule 3\n",
      "w [1 1 1 1 1 1 1]\n",
      "\n",
      "[0 1 2 6 5 4 3]\n",
      "g3:\n",
      "clique False\n",
      "1^up_tack (True, 2)\n",
      "g4:\n",
      "[[0 1 1 1 1 0 0 0]\n",
      " [1 0 1 1 1 1 0 0]\n",
      " [1 1 0 1 1 1 1 0]\n",
      " [1 1 1 0 1 1 1 1]\n",
      " [1 1 1 1 0 1 1 1]\n",
      " [0 1 1 1 1 0 1 1]\n",
      " [0 0 1 1 1 1 0 1]\n",
      " [0 0 0 1 1 1 1 0]]\n",
      "clique True\n",
      "1^up_tack (True, 1)\n",
      "i, n, m, valency, valencies, e, modified, firstzero, lastzero\n",
      "\n",
      "5.5 4.0\n",
      "0 8 4.0 4 [4 5 6 7 7 6 5 4] [-1 -1 -1 -1 -1 -1 -1 -1] [1 1 1 1 1 1 1 1] 8 0 -1\n",
      "rule 5\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "5.142857142857143 4.0\n",
      "1 7 4.0 4 [0 4 5 6 6 6 5 4] [ 0 -1 -1 -1 -1 -1 -1 -1] [0 1 1 1 1 1 1 1] 7 1 -1\n",
      "rule 5\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "4.666666666666667 4.0\n",
      "2 6 4.0 4 [0 0 4 5 5 5 5 4] [ 0  1 -1 -1 -1 -1 -1 -1] [0 0 1 1 1 1 1 1] 6 2 -1\n",
      "rule 5\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "4.0 4.0\n",
      "3 5 4.0 4 [0 0 0 4 4 4 4 4] [ 0  1  2 -1 -1 -1 -1 -1] [0 0 0 1 1 1 1 1] 5 3 -1\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "3.0 4.0\n",
      "4 4 3.0 3 [0 0 0 0 3 3 3 3] [ 0  1  2 -1 -1 -1 -1  3] [0 0 0 0 1 1 1 1] 4 3 -2\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "2.0 4.0\n",
      "5 3 2.0 2 [0 0 0 0 0 2 2 2] [ 0  1  2 -1 -1 -1  4  3] [0 0 0 0 0 1 1 1] 3 3 -3\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "1.0 4.0\n",
      "6 2 1.0 1 [0 0 0 0 0 0 1 1] [ 0  1  2 -1 -1  5  4  3] [0 0 0 0 0 0 1 1] 2 3 -4\n",
      "rule 1\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "nan 3.0\n",
      "7 0 nan 0 [0 0 0 0 0 0 0 0] [ 0  1  2 -1  6  5  4  3] [0 0 0 0 0 0 0 1] 1 3 -5\n",
      "rule 3\n",
      "w [1 1 1 1 1 1 1 1]\n",
      "\n",
      "[0 1 2 7 6 5 4 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:189: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "\"\"\"testing the merge rule (r6) using banded matrix\"\"\"\n",
    "graph_2 = np.array([[0,1,1,1,0,0,0],\n",
    "                    [1,0,1,1,1,0,0],\n",
    "                    [1,1,0,1,1,1,0],\n",
    "                    [1,1,1,0,1,1,1],\n",
    "                    [0,1,1,1,0,1,1],\n",
    "                    [0,0,1,1,1,0,1],\n",
    "                    [0,0,0,1,1,1,0]\n",
    "                   ])\n",
    "print(\"g2:\")\n",
    "print(\"symm\", np.allclose(graph_2, graph_2.T, rtol=1e-05, atol=1e-08))\n",
    "print(\"clique\", clique_check(graph_2, [1,2,3]))\n",
    "print(\"1^up_tack\", check_subset(graph_2, [1,2,3]))\n",
    "e, w, first_zero, last_zero, merge_forest = initialize(graph_2)\n",
    "print(normalize(graph_2, e, w, first_zero, last_zero, merge_forest))\n",
    "\n",
    "\n",
    "graph_3 = np.array([[0,1,1,1],\n",
    "                    [1,0,1,0],\n",
    "                    [1,1,0,1],\n",
    "                    [1,0,1,0]])\n",
    "print(\"g3:\")\n",
    "print(\"clique\", clique_check(graph_3, [1,2,3]))\n",
    "print(\"1^up_tack\", check_subset(graph_3, [1,2,3]))\n",
    "\n",
    "#test using another bamded matrix\n",
    "from scipy.sparse import diags\n",
    "graph_4 = diags([1,1,1, 1, 0, 1, 1,1,1], [-4,-3,-2,-1, 0, 1,2,3,4], shape=(8, 8), dtype=int).toarray()\n",
    "print(\"g4:\")\n",
    "print(graph_4)\n",
    "print(\"clique\", clique_check(graph_4, [1,2,3]))\n",
    "print(\"1^up_tack\", check_subset(graph_4, [1,2,3]))\n",
    "e, w, first_zero, last_zero, merge_forest = initialize(graph_4)\n",
    "print(normalize(graph_4, e, w, first_zero, last_zero, merge_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e,w,first_zero, last_zero, merge_forest, deleted: \n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 18 10  1  3] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 0 -5 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] (array([ 1,  3, 10, 18], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "'''dijkstra https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm''' \n",
    "#function to help djikstra algorithm:\n",
    "def get_min_distance_vertex(Q, distances):\n",
    "    min_dist = float(\"inf\")\n",
    "    min_v = None\n",
    "    for v in range(Q.shape[0]):\n",
    "        if (distances[v] < min_dist) and (Q[v] == 1):\n",
    "            min_dist = distances[v]\n",
    "            min_v = v\n",
    "    return min_dist, min_v\n",
    "\n",
    "#start of dijkstra algorithm:\n",
    "def dijkstra_shortest_path(graph, source):\n",
    "    #n_init = get_total_nodes(graph, graph.shape[0])\n",
    "    n_init = graph.shape[0]\n",
    "    Q = np.array([1]*n_init)\n",
    "    #print(Q)\n",
    "    #source = root = 0\n",
    "    distances = np.array([float(\"inf\")]*n_init) #set distance vector\n",
    "    distances[source] = 0\n",
    "    prev = np.array([None]*n_init)\n",
    "\n",
    "    while np.sum(Q) > 0:\n",
    "        _, u = get_min_distance_vertex(Q, distances) #get the vertex with minimum distance\n",
    "        Q[u] = False #remove u from Q\n",
    "        neighbours = np.where(graph[u] == 1)[0]\n",
    "#        print(\"len(Q), neighbours\",len(Q), neighbours)\n",
    "        for v in neighbours:\n",
    "            if Q[v] == 1:\n",
    "                alt = distances[u] + graph[u][v] #distance is equal to the weight of the edge between u and v\n",
    "                if alt < distances[v]:\n",
    "                    distances[v] = alt\n",
    "                    prev[v] = u\n",
    "                #print(alt)\n",
    "    return distances, prev\n",
    "\n",
    "#function to find max valency from nodes\n",
    "def get_max_valency(subset_nodes, valencies):\n",
    "    max_valency = -float(\"inf\")\n",
    "    max_vertex = None\n",
    "    for m in subset_nodes:\n",
    "        if valencies[m] > max_valency:\n",
    "            max_valency = valencies[m]\n",
    "            max_vertex = m\n",
    "    return max_vertex, max_valency\n",
    "\n",
    "'''Separate Stage'''\n",
    "def separate(graph):\n",
    "    global deleted, e, w, first_zero, last_zero, merge_forest\n",
    "    n_init = graph.shape[0] #actual graph size\n",
    "    \n",
    "    '''RCM part'''\n",
    "    #1, d=0, pick vertex e with max valency:\n",
    "    #print(\"#1: \")\n",
    "    d_prime = 0\n",
    "    n_nodes = get_total_nodes(graph, graph.shape[0]) #current total nodes\n",
    "    valencies = np.array([np.sum(graph[i]) for i in range(n_init)])\n",
    "    e_sep = np.argmax(valencies) #get the node with max valency\n",
    "\n",
    "    #2, need to find a set of M with max distansce from e, which requires BFS or djikstra:\n",
    "    #print(\"#2: \")\n",
    "    distances, _ = dijkstra_shortest_path(graph, e_sep)\n",
    "    #print(\"distances\",distances)\n",
    "    conn_components = np.where(distances != np.inf)[0] #indexes of connected components within the subgraph where e resides\n",
    "    conn_distances = distances[conn_components] #distances of connected components (distances excluding inf)\n",
    "    s = conn_components.shape[0] #total connected components\n",
    "    d = np.max(conn_distances) #max distance from e\n",
    "    M = np.where(distances == d)[0] #set of vertices with max distance from e\n",
    "    #print(\"n_init, valencies, e_sep, s, d, M, conn_distances\")\n",
    "    #print(n_init, valencies, e_sep, s, d, M, conn_distances)\n",
    "    \n",
    "    \n",
    "    #3, if d'>d, d'=d, pick a vertex from M with max valency, back to 2 if the first e is close to the second e\n",
    "    #print(\"#3: \")\n",
    "    loopcount = 0 #for repetition statistics\n",
    "    while d>d_prime:\n",
    "        #print(\"d, d_prime, e_sep\",d, d_prime, e_sep)\n",
    "        d_prime = d\n",
    "        max_vertex,_ = get_max_valency(M, valencies)\n",
    "        #print(\"M, valencies\",M, valencies)\n",
    "        e_sep = max_vertex\n",
    "\n",
    "        #do 2 again:\n",
    "        distances, _ = dijkstra_shortest_path(graph, e_sep)\n",
    "        conn_components = np.where(distances != np.inf)[0] #indexes of connected components within the subgraph where e resides\n",
    "        conn_distances = distances[conn_components] #distances of connected components (distances excluding inf)\n",
    "        s = conn_components.shape[0] #total connected components\n",
    "        d = np.max(conn_distances) #max distance from e\n",
    "        M = np.where(distances == d)[0] #set of vertices with max distance from e\n",
    "        loopcount+=1\n",
    "    #print(\"RCM loopcount\", loopcount)\n",
    "    #print(\"n_init, valencies, e_sep, s, d, M, conn_distances\")\n",
    "    #print(n_init, valencies, e_sep, s, d, M, conn_distances)\n",
    "    '''end of RCM'''\n",
    "\n",
    "    \n",
    "    #3.5, get the n_k from e, 0<=k<=d, d=max distance, k \\in Z\n",
    "    #print(\"#3.5: n_k from e, 0<=k<=d, d=max distance\")\n",
    "    max_d = np.max(conn_distances).astype(int)\n",
    "    n_arr = np.zeros(max_d+1)\n",
    "    for i in range(0,max_d+1):\n",
    "        n_arr[i] = np.where(conn_distances == i)[0].shape[0]\n",
    "    #print(\"n_arr\",n_arr)\n",
    "    \n",
    "    \n",
    "    #4, initialization of several variables:\n",
    "    ##NOTE: there are two n's, n_k and n_{k+1}, which will be used for comparison in a condition.\n",
    "    #print(\"#4: \")\n",
    "    k=0; N=[np.array([e_sep])]; n=[1]; u = s-1; tried = np.array([0]*n_init); tried[e_sep] = 1\n",
    "    \n",
    "    seploop = 0\n",
    "    while True:\n",
    "        #first line:\n",
    "        #gamma_{k+1}(e):=get neighbours/set of points from e with the distance of k+1\n",
    "        N_next = np.where(distances == k+1)[0] #get the set of neighbours with distance = k+1\n",
    "        N.append(N_next)\n",
    "        n.append(len(N[k+1])) #or sum of weights?\n",
    "        u -= n[k+1]\n",
    "        #print(\"k,N,n,u\",k,N,n,u)\n",
    "\n",
    "        #print(\"n_arr[k] <= n_arr[k+1] < n_arr[k+2]\",n_arr[k] <= n_arr[k+1] < n_arr[k+2])\n",
    "        \n",
    "        #print(\"k+2, len(n_arr), d\",k+2, len(n_arr), d)\n",
    "        '''if k+2 < len(n_arr): #temporary fix, by skipping the block if k+2 >= len(n)\n",
    "            if (n_arr[k] <= n_arr[k+1] < n_arr[k+2]):\n",
    "                k += 1\n",
    "                continue'''\n",
    "        if (k < d-1) and (n_arr[k] <= n_arr[k+1] < n_arr[k+2]) and (u > 0.4*s): #another fix, by adding more skip-conditions\n",
    "            #print(\"(k < d-1) and (n_arr[k] <= n_arr[k+1] < n_arr[k+2]) and (u > 0.4*s) condition reached\")\n",
    "            k += 1\n",
    "            continue\n",
    "        \n",
    "        #second line, determining \"in degrees\":\n",
    "        #c = {} #need to know which c corresponds to which node, so probably use a dictionary\n",
    "        c = np.zeros(n_init)\n",
    "        j_idxs = N[k+1] #to keep track the used node indexes\n",
    "        for node_j in N[k+1]: #indexing not by nodes' indices, but by c's internal index\n",
    "            gamma_j = np.where(graph[node_j] == 1)[0]\n",
    "            c[node_j] = (np.intersect1d(gamma_j, N[k])).shape[0]\n",
    "            #print(\"gamma_j, N[k]\",gamma_j, N[k])\n",
    "        #print(\"c[j_idxs]\",c[j_idxs])\n",
    "\n",
    "        #third line, determining the \"out-weights\" (weights from normalization stage):\n",
    "        #b = {} #same reason with c\n",
    "        b = np.zeros(n_init)\n",
    "        i_idxs = N[k]\n",
    "        for node_i in N[k]:\n",
    "            gamma_i = np.where(graph[node_i] == 1)[0]\n",
    "            out_w_nodes = np.intersect1d(gamma_i, N[k+1])\n",
    "            b[node_i] = np.sum(w[out_w_nodes]) #w = weights from normalization, need to know which value belongs to which\n",
    "            #print(\"gamma_i, N[k+1]\",gamma_i, N[k+1])\n",
    "        #print(\"b\",b)\n",
    "        \n",
    "        \n",
    "        #fourth line:\n",
    "        while n[k] > 0:\n",
    "            #print(\"n[k]>0\",n[k] > 0)\n",
    "            if (u > 0.4*s) and (n[k+1] < n[k]): #threshold = 0.4s\n",
    "                #print(\"(u > 0.4*s) and (n[k+1] < n[k])\",(u > 0.4*s) and (n[k+1] < n[k]))\n",
    "                break\n",
    "            #place i with largest b_i last: (the rule should follow the placement rule in normalization)\n",
    "            #new condition to check, when b_i = 0, then break:\n",
    "            if np.sum(b) == 0:\n",
    "                #print(\"b_i all zero\")\n",
    "                #print(\"k,d,b,c\",k,d,b,c)\n",
    "                break\n",
    "            #\n",
    "            placed = np.argmax(b)\n",
    "            #print(\"placed\",placed)\n",
    "            ##start of temporary fix\n",
    "            #if b[placed] > 0: #meaning, gamma(i) \\intersect N_{k+1} is not {}\n",
    "            if w[placed] > 1:\n",
    "                ordered_list = get_ordered_list_merged_vertex(merge_forest, placed)\n",
    "                len_e = len(e)\n",
    "                len_ord_list = len(ordered_list)\n",
    "                e[len_e + last_zero - len_ord_list + 1 : len_e + last_zero + 1] = ordered_list\n",
    "                last_zero -= len_ord_list\n",
    "            else:\n",
    "                e[last_zero] = placed\n",
    "                last_zero -= 1\n",
    "            graph[placed] = graph[:,placed] = 0\n",
    "            deleted[placed] = True\n",
    "            b[placed] = 0 #remove from b\n",
    "            #print(\"e,fz,lz after placement:\",e,first_zero,last_zero)\n",
    "            #decrement s, n_k, c_j:\n",
    "            #print(\"s,n[k],c\",s,n[k],c)\n",
    "            s -= 1; n[k] -= 1; c[N[k+1]] -= 1\n",
    "            ##end of temporary fix#\n",
    "            #print(\"s,n[k],c\",s,n[k],c)\n",
    "            #if c_j == 0: ......\n",
    "            #drop c_j from N; incr u; decr n[k+1]:\n",
    "            for node_j in N[k+1]:\n",
    "                if c[node_j] == 0:\n",
    "                    N[k+1] = N[k+1][N[k+1] != node_j] #drop cj from N\n",
    "                    u += 1; n[k+1] -= 1\n",
    "                    #print(\"N, u, n, c[node_j]\",N, u, n, c[node_j])\n",
    "        if n[k] == 0: ##NOTE: this part is a little bit uncanny, since in first iter the n[k] will always reach 0\n",
    "            break\n",
    "        tried[N[k]] = 1; k += 1 #mark all i \\in N_k as tried, increment k\n",
    "        seploop+=1\n",
    "        #print(\"\\n seploop\",seploop)\n",
    "\n",
    "    #print(e)\n",
    "    #return graph, e, w, first_zero, last_zero, merge_forest\n",
    "    return first_zero, last_zero\n",
    "            #break #for loop breaking purpose during tests -- removed on actual scenario\n",
    "        #break #for loop breaking purpose during tests -- removed on actual scenario\n",
    "\n",
    "'''dummy data'''\n",
    "graph = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "             ])\n",
    "\n",
    "#nauru graph (bipartite)\n",
    "graph_1 = np.zeros((24,24))\n",
    "graph_1[0][1] = graph_1[0][5] = graph_1[0][21] = \\\n",
    "graph_1[1][3] = graph_1[1][15] = \\\n",
    "graph_1[2][3] = graph_1[2][4] = graph_1[2][23] = \\\n",
    "graph_1[3][9] = graph_1[4][5] = graph_1[4][17] = \\\n",
    "graph_1[5][11] = graph_1[6][7] = graph_1[6][11] = graph_1[6][19] = \\\n",
    "graph_1[7][9] = graph_1[7][13] = \\\n",
    "graph_1[8][9] = graph_1[8][10] = graph_1[8][22] = \\\n",
    "graph_1[10][11] = graph_1[10][16] = \\\n",
    "graph_1[12][13] = graph_1[12][17] = graph_1[12][18] = \\\n",
    "graph_1[13][15] = graph_1[14][15] = graph_1[14][16] = graph_1[14][20] = \\\n",
    "graph_1[16][17] = graph_1[18][19] = graph_1[18][23] = \\\n",
    "graph_1[19][21] = graph_1[20][21] = graph_1[20][22] = \\\n",
    "graph_1[22][23] = 1\n",
    "graph_1 += graph_1.T\n",
    "#print(np.allclose(graph_1, graph_1.T, rtol=1e-05, atol=1e-08))\n",
    "graph = graph_1\n",
    "\n",
    "'''\n",
    "graph = np.array([[0,1,1,1,0,0,0],\n",
    "                    [1,0,1,1,1,0,0],\n",
    "                    [1,1,0,1,1,1,0],\n",
    "                    [1,1,1,0,1,1,1],\n",
    "                    [0,1,1,1,0,1,1],\n",
    "                    [0,0,1,1,1,0,1],\n",
    "                    [0,0,0,1,1,1,0]\n",
    "                   ])\n",
    "'''\n",
    "\n",
    "'''n_init = graph.shape[0]\n",
    "w = np.array([1]*n_init)\n",
    "first_zero = 0; last_zero = -1\n",
    "e = np.zeros(n_init)'''\n",
    "e,w,first_zero, last_zero, merge_forest, deleted = initialize(graph) \n",
    "'''end of dummy data'''\n",
    "\n",
    "separate(graph)\n",
    "print(\"e,w,first_zero, last_zero, merge_forest, deleted: \\n\",e,w,first_zero, last_zero, merge_forest, np.where(deleted == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining both normalize and separate stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eli 1 [1 2 5 7 6 0 4 3]\n",
      "time elapsed for elimination ordering:  0.0019943714141845703 s\n",
      "metis 0 [2 1 0 5 3 7 4 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:200: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "'''input data: '''\n",
    "'''graph = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "             ])'''\n",
    "#nauru graph (bipartite)\n",
    "graph_1 = np.zeros((24,24))\n",
    "graph_1[0][1] = graph_1[0][5] = graph_1[0][21] = \\\n",
    "graph_1[1][3] = graph_1[1][15] = \\\n",
    "graph_1[2][3] = graph_1[2][4] = graph_1[2][23] = \\\n",
    "graph_1[3][9] = graph_1[4][5] = graph_1[4][17] = \\\n",
    "graph_1[5][11] = graph_1[6][7] = graph_1[6][11] = graph_1[6][19] = \\\n",
    "graph_1[7][9] = graph_1[7][13] = \\\n",
    "graph_1[8][9] = graph_1[8][10] = graph_1[8][22] = \\\n",
    "graph_1[10][11] = graph_1[10][16] = \\\n",
    "graph_1[12][13] = graph_1[12][17] = graph_1[12][18] = \\\n",
    "graph_1[13][15] = graph_1[14][15] = graph_1[14][16] = graph_1[14][20] = \\\n",
    "graph_1[16][17] = graph_1[18][19] = graph_1[18][23] = \\\n",
    "graph_1[19][21] = graph_1[20][21] = graph_1[20][22] = \\\n",
    "graph_1[22][23] = 1\n",
    "graph_1 += graph_1.T\n",
    "#print(np.allclose(graph_1, graph_1.T, rtol=1e-05, atol=1e-08))\n",
    "\n",
    "#custom graph\n",
    "graph_2 = np.array([\n",
    "    [0,1,0,0,1,0,1,1],\n",
    "    [1,0,0,0,1,0,0,1],\n",
    "    [0,0,0,0,0,0,0,1],\n",
    "    [0,0,0,0,1,1,1,1],\n",
    "    [1,1,0,1,0,1,1,1],\n",
    "    [0,0,0,1,1,0,1,0],\n",
    "    [1,0,0,1,1,1,0,1],\n",
    "    [1,1,1,1,1,0,1,0]\n",
    "])\n",
    "\n",
    "def elimination_ordering(graph, log=False):\n",
    "    #alternate normalize and separate while the graph is not empty\n",
    "    i=0\n",
    "    while np.sum(graph) > 0:\n",
    "        if np.sum(graph) == 0:\n",
    "            break\n",
    "        if log:\n",
    "            print(\"Normalize:\")\n",
    "        normalize(graph)\n",
    "        if log:\n",
    "            print(\"e, w, first_zero, last_zero, deleted\", e, w, first_zero, last_zero, np.where(deleted == True))\n",
    "        if np.sum(graph) == 0:\n",
    "            break\n",
    "        if log:\n",
    "            print(\"\\n Separate:\")\n",
    "        separate(graph)\n",
    "        if log:\n",
    "            print(\"e, w, first_zero, last_zero, deleted \\n\", e, w, first_zero, last_zero, np.where(deleted == True))\n",
    "        #print(graph, merge_forest)\n",
    "        if log:\n",
    "            print(\"==================NEW ROUND======================= \\n\")\n",
    "        print(\"stage iteration:\",i)\n",
    "        i += 1\n",
    "    return e\n",
    "\n",
    "'''initialization'''\n",
    "graph = graph_2\n",
    "graph_elim = np.copy(graph)\n",
    "graph_elim2 = np.copy(graph_elim)\n",
    "e, w, first_zero, last_zero, merge_forest, deleted = initialize(graph) #must be on global scope\n",
    "\n",
    "'''ordered elimination'''\n",
    "start = time.time()\n",
    "elimination_ordering(graph)\n",
    "fills, _ = eliminate(graph_elim, e)\n",
    "print(\"eli\",fills,e)\n",
    "end = time.time()\n",
    "print(\"time elapsed for elimination ordering: \",end - start,\"s\")\n",
    "\n",
    "\n",
    "'''test using metis'''\n",
    "#adj_mat_to_metis_file(graph_elim2, \"custgraph.metisgraph\")\n",
    "#metis_order = iperm_to_orderlist(\"matrices/nauru_bipartite.metisgraph.iperm\")\n",
    "metis_order = iperm_to_orderlist(\"matrices/custgraph.metisgraph.iperm\")\n",
    "fills, _ = eliminate(graph_elim2, metis_order)\n",
    "print(\"metis\", fills, metis_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fill: 3\n",
      "total fill: 0\n",
      "[7 1 3 0 2 6 5 4]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'matrices/bcsstk01.mtx.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-297800584a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miperm_to_orderlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"matrices/disconn_graph.metisgraph.iperm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_matrix_market\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"matrices/bcsstk01.mtx.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-297800584a07>\u001b[0m in \u001b[0;36mload_matrix_market\u001b[1;34m(filename, get_mat_meta)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;34m'''test using matrices from matrix market'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m#filename = \"matrices/bcsstm01.mtx.gz\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmminfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmmread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36mmminfo\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mEither\u001b[0m \u001b[1;34m'general'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'symmetric'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'skew-symmetric'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'hermitian'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36minfo\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \"\"\"\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(filespec, mode)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfilespec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                     \u001b[1;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                     \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mfilespec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.bz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                     \u001b[1;32mimport\u001b[0m \u001b[0mbz2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'matrices/bcsstk01.mtx.gz'"
     ]
    }
   ],
   "source": [
    "def eliminate(graph, elimination_order):\n",
    "    '''elimination function: eliminates the vertices based on the order resulted from elimination ordering algorithms\n",
    "    - takes in the vertices order from the any elimination ordering algorithms (e.g. METIS' nested dissection)\n",
    "    - fill will be added when the \"center\" of the vertex is eliminated, e.g., 1-2-3, eliminate 2, fill(1-3), fill_count+=1\n",
    "    - for now, assume the fill will be comb(n,2), so if there are 3 vertices which depend on an eliminated vertex, there will be 6 fills\n",
    "    '''\n",
    "    count_fill = 0\n",
    "    for node_i in elimination_order:\n",
    "        #find neighbours and fill the fill-in indexes:\n",
    "        neighbours = np.where(graph[node_i] == 1)[0]\n",
    "        fill_idxs = list(combinations(neighbours, 2))\n",
    "        #fill-in the edge of i's neighbours:\n",
    "        if len(fill_idxs) > 0:\n",
    "            #check if the edges are present, if there are no edges, add them:\n",
    "            for fill in fill_idxs:\n",
    "                if graph[fill[0]][fill[1]] == 0:\n",
    "                    graph[fill[0]][fill[1]] = graph[fill[1]][fill[0]] = 1\n",
    "                    count_fill += 1\n",
    "        #remove the edges of i:\n",
    "        graph[node_i] = graph[:,node_i] = 0\n",
    "    return count_fill, graph\n",
    "\n",
    "def adj_mat_to_metis_file(graph, filename):\n",
    "    '''write adjacency matrix to file'''\n",
    "    first_line = np.array([graph.shape[0], int(np.sum(graph)/2)]) #[nodes, edges]\n",
    "    adj_list = []\n",
    "    for i in range(graph.shape[0]):\n",
    "        neighbours = np.where(graph[i] == 1)[0]\n",
    "        neighbours += 1\n",
    "        adj_list.append(neighbours)\n",
    "    adj_list = np.array(adj_list)\n",
    "    \n",
    "    with open(filename,\"w\") as f:\n",
    "        f.write(str(first_line[0])+\" \"+str(first_line[1])+\"\\n\")\n",
    "        for i in range(adj_list.shape[0]):\n",
    "            for j in range(adj_list[i].shape[0]):\n",
    "                f.write(str(adj_list[i][j])+\" \")\n",
    "            f.write(\"\\n\")\n",
    "    print(\"writing\",filename,\"done!\")\n",
    "\n",
    "def iperm_to_orderlist(filename):\n",
    "    '''read iperm from ndmetis and convert it to list'''\n",
    "    f = open(filename, \"r\")\n",
    "    order = []\n",
    "    for x in f:\n",
    "        order.append(int(x))\n",
    "    order = np.array(order)\n",
    "    #according to metis documentatoin:\n",
    "    actual_order = np.zeros(order.shape[0])\n",
    "    for i in range(order.shape[0]):\n",
    "        actual_order[i] = np.where(order == i)[0]\n",
    "    actual_order = actual_order.astype(np.int64, copy=False)\n",
    "    return actual_order\n",
    "\n",
    "def load_matrix_market(filename, get_mat_meta=False):\n",
    "    '''test using matrices from matrix market'''\n",
    "    #filename = \"matrices/bcsstm01.mtx.gz\"\n",
    "    metadata = mminfo(filename)\n",
    "    Matrix = mmread(filename)\n",
    "    A = Matrix.toarray()\n",
    "    #print(A)\n",
    "    #print(np.nonzero(A))\n",
    "    '''preprocess the matrix'''\n",
    "    A = A.astype(np.int64, copy=False)\n",
    "    #symmetrize the matrix:\n",
    "    A = A + A.T\n",
    "    #print(\"symmetrize:\")\n",
    "    #print(A)\n",
    "    #set diagonals to zero:\n",
    "    np.fill_diagonal(A, 0)\n",
    "    #print(\"diag\")\n",
    "    #print(A)\n",
    "    #if a nonzero element is >0 or <0, set it to 1:\n",
    "    #print(\"nz\")\n",
    "    A[np.nonzero(A)] = 1\n",
    "    #print(A)\n",
    "    if get_mat_meta:\n",
    "        return A, metadata\n",
    "    else:\n",
    "        return A\n",
    "\n",
    "graph = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "             ])\n",
    "order = [2, 3, 4, 5, 6, 8, 1, 0, 7] #from the elimination ordering result\n",
    "countfill,_ = eliminate(graph, order)\n",
    "print(\"total fill:\" ,countfill)\n",
    "\n",
    "#banded matrix 2m+1 = 15\n",
    "graph_2 = np.array([[0,1,1,1,0,0,0],\n",
    "                    [1,0,1,1,1,0,0],\n",
    "                    [1,1,0,1,1,1,0],\n",
    "                    [1,1,1,0,1,1,1],\n",
    "                    [0,1,1,1,0,1,1],\n",
    "                    [0,0,1,1,1,0,1],\n",
    "                    [0,0,0,1,1,1,0]\n",
    "                   ])\n",
    "order = [0, 1, 2, 6, 5, 4, 3]\n",
    "countfill,_ = eliminate(graph, order)\n",
    "print(\"total fill:\" ,countfill)\n",
    "\n",
    "print(iperm_to_orderlist(\"matrices/disconn_graph.metisgraph.iperm\"))\n",
    "\n",
    "A = load_matrix_market(\"matrices/bcsstk01.mtx.gz\")\n",
    "print(np.nonzero(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bcsstk01.mtx.gz', 'bcsstm13.mtx.gz', 'ck104.mtx.gz', 'mcca.mtx.gz', 'mcfe.mtx.gz', 'qc2534.mtx.gz', 'qc324.mtx.gz', 'zenios.mtx.gz']\n",
      "(48, 48, 224, 'coordinate', 'real', 'symmetric')\n",
      "True\n",
      "writing matrices/ndmetis_input/bcsstk01.mtx.gz.metisgraph done!\n",
      "(2003, 2003, 11973, 'coordinate', 'real', 'symmetric')\n",
      "True\n",
      "writing matrices/ndmetis_input/bcsstm13.mtx.gz.metisgraph done!\n",
      "(104, 104, 992, 'coordinate', 'real', 'general')\n",
      "True\n",
      "writing matrices/ndmetis_input/ck104.mtx.gz.metisgraph done!\n",
      "(180, 180, 2659, 'coordinate', 'real', 'general')\n",
      "True\n",
      "writing matrices/ndmetis_input/mcca.mtx.gz.metisgraph done!\n",
      "(765, 765, 24382, 'coordinate', 'real', 'general')\n",
      "True\n",
      "writing matrices/ndmetis_input/mcfe.mtx.gz.metisgraph done!\n",
      "(2534, 2534, 463360, 'coordinate', 'complex', 'general')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "writing matrices/ndmetis_input/qc2534.mtx.gz.metisgraph done!\n",
      "(324, 324, 26730, 'coordinate', 'complex', 'general')\n",
      "True\n",
      "writing matrices/ndmetis_input/qc324.mtx.gz.metisgraph done!\n",
      "(2873, 2873, 15032, 'coordinate', 'real', 'symmetric')\n",
      "True\n",
      "writing matrices/ndmetis_input/zenios.mtx.gz.metisgraph done!\n"
     ]
    }
   ],
   "source": [
    "'''matrices pre-processing'''\n",
    "mypath = \"matrices/mm/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(onlyfiles)\n",
    "#for all matrices, load:\n",
    "for f in onlyfiles:\n",
    "    G = load_matrix_market(\"matrices/mm/\"+f)\n",
    "    #print(np.diagonal(G))\n",
    "    print(np.allclose(G, G.T, rtol=1e-05, atol=1e-08))\n",
    "\n",
    "    #save all matrices to metis format:\n",
    "    adj_mat_to_metis_file(G, \"matrices/ndmetis_input/\"+f+\".metisgraph\")\n",
    "\n",
    "    #run the metis using all the matrices elsewhere.....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bcsstk01.mtx.gz' 'bcsstm13.mtx.gz' 'ck104.mtx.gz' 'mcca.mtx.gz'\n",
      " 'mcfe.mtx.gz' 'zenios.mtx.gz']\n",
      "stage iteration: 0\n",
      "stage iteration: 1\n",
      "stage iteration: 2\n",
      "stage iteration: 3\n",
      "stage iteration: 4\n",
      "stage iteration: 5\n",
      "stage iteration: 6\n",
      "stage iteration: 7\n",
      "stage iteration: 8\n",
      "stage iteration: 9\n",
      "eli 419 [25 29 26 10 22 40  9 38 39 41 43 47  7 21 27 19 42 23 31  2 20  4  6  0\n",
      " 30 24 28 11  5  3 37 44 33 15 18 17  8 36 32 13 16 46 45 35 34 12  1 14]\n",
      "time elapsed for elimination ordering:  0.22521209716796875 s\n",
      "metis 265 [26 25 38  7 27 37 21 33 43  9 45  3 13 31 32 15 39 44 29 28 36 23 10 24\n",
      " 22  6  5 46 42 18 47  0  4 12 16 30 11  2 41 34 20 14 17  8 40  1 35 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:200: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eli 0 [   0    1    2 ... 2001 2002 1899]\n",
      "time elapsed for elimination ordering:  37.22604465484619 s\n",
      "metis 0 [1971 1953 1952 ...  115   13    9]\n",
      "eli 0 [  0   1   2   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103   3]\n",
      "time elapsed for elimination ordering:  0.08307552337646484 s\n",
      "metis 0 [103  99  90  89  88  86  85  84  83  82  81  80  77  76  75  74  73  72\n",
      "  71  70  69  68  64  61  58  55  54  53  46  45  42  41  40  39  38  37\n",
      "  31  29  26  25  24  23  22  21  20  12  11   8   4   2   1   0 102 101\n",
      " 100  98  97  96  95  94  93  92  91  87  79  78  67  66  65  63  62  60\n",
      "  59  57  56  52  51  50  49  48  47  44  43  36  35  34  33  32  30  28\n",
      "  27  19  18  17  16  15  14  13  10   9   7   6   5   3]\n",
      "stage iteration: 0\n",
      "stage iteration: 1\n",
      "stage iteration: 2\n",
      "stage iteration: 3\n",
      "stage iteration: 4\n",
      "stage iteration: 5\n",
      "stage iteration: 6\n",
      "stage iteration: 7\n",
      "stage iteration: 8\n",
      "stage iteration: 9\n",
      "stage iteration: 10\n",
      "stage iteration: 11\n",
      "stage iteration: 12\n",
      "stage iteration: 13\n",
      "stage iteration: 14\n",
      "eli 964 [  0   1   2   3   4   5   6   7   8   9  10  11  13  12  14  15  17  19\n",
      "  21  23  25  27  29  31  33  35  39  43  47  51  55  59  63  67  71  75\n",
      "  79  83  87  91  95  99 103 107 111 115 119 123 127 131 135 139 143 147\n",
      " 151 155 159 163 167 171 175 176 177 178 179  28 172 173 174  16  20  18\n",
      "  22 169  40  60  76 108 112  32  24  26  36  30  34 116 120 124  49  88\n",
      " 104 128  92  96 100 144 148 152  44  37  48  41  38  42 156 160 145 146\n",
      " 149 170 158 161 165 166 125 122 121 118 117 109 113 157 153 164 150 140\n",
      " 141 101  97  93  85 136 137 168 162 105  81  73 154 129 133 142 138  56\n",
      "  52  45  46  77  69  65  89 114 110  53  57 134 130 126 132  61  80 102\n",
      " 106  64  50  68  54  84  72  58  62  98  94  86  82  78  90  74  70  66]\n",
      "time elapsed for elimination ordering:  1.712557315826416 s\n",
      "metis 334 [119 115 111 107 103  99  95  91  87  83  79  75  71  67  63  59  55  51\n",
      "  47  43  39  35  33  31  29  27  25  23  21  19  17  15  13  11   8   9\n",
      "  10 116  12  14 112  24  20  16  37  18  41  28  32  22  26  30  36  84\n",
      "  80  76  40 108  44  72 104  68  64  48  45 100  96  60  56  52  92  88\n",
      "  49  34  38 117  53  93  57  61  65  69  89  81  85 109 113  73  77  97\n",
      " 101  42 105  46  50  54  58  62  66  70  74  78  82  86  90  94  98 102\n",
      " 139 135 131 128 127 124 123 120 132 179 175 171 167 163 159 155 151 147\n",
      " 143 136   7   4   5   6   3   0   1   2 176 172 140 177 178 173 174 144\n",
      " 168 152 148 169 156 164 160 170 141 165 145 166 161 162 157 149 158 150\n",
      " 153 154 146 142 114 106 138 126 129 137 122 118 130 134 110 125 121 133]\n",
      "stage iteration: 0\n",
      "stage iteration: 1\n",
      "stage iteration: 2\n",
      "stage iteration: 3\n",
      "stage iteration: 4\n",
      "stage iteration: 5\n",
      "stage iteration: 6\n",
      "stage iteration: 7\n",
      "stage iteration: 8\n",
      "stage iteration: 9\n",
      "stage iteration: 10\n",
      "stage iteration: 11\n",
      "stage iteration: 12\n",
      "stage iteration: 13\n",
      "stage iteration: 14\n",
      "stage iteration: 15\n",
      "stage iteration: 16\n",
      "stage iteration: 17\n",
      "stage iteration: 18\n",
      "stage iteration: 19\n",
      "stage iteration: 20\n",
      "stage iteration: 21\n",
      "stage iteration: 22\n",
      "stage iteration: 23\n",
      "stage iteration: 24\n",
      "stage iteration: 25\n",
      "stage iteration: 26\n",
      "stage iteration: 27\n",
      "stage iteration: 28\n",
      "stage iteration: 29\n",
      "stage iteration: 30\n",
      "stage iteration: 31\n",
      "stage iteration: 32\n",
      "stage iteration: 33\n",
      "stage iteration: 34\n",
      "stage iteration: 35\n",
      "stage iteration: 36\n",
      "stage iteration: 37\n",
      "stage iteration: 38\n",
      "stage iteration: 39\n",
      "stage iteration: 40\n",
      "stage iteration: 41\n",
      "stage iteration: 42\n",
      "stage iteration: 43\n",
      "stage iteration: 44\n",
      "stage iteration: 45\n",
      "stage iteration: 46\n",
      "stage iteration: 47\n",
      "stage iteration: 48\n",
      "stage iteration: 49\n",
      "stage iteration: 50\n",
      "stage iteration: 51\n",
      "stage iteration: 52\n",
      "stage iteration: 53\n",
      "stage iteration: 54\n",
      "stage iteration: 55\n",
      "stage iteration: 56\n",
      "stage iteration: 57\n",
      "stage iteration: 58\n",
      "stage iteration: 59\n",
      "stage iteration: 60\n",
      "stage iteration: 61\n",
      "stage iteration: 62\n",
      "stage iteration: 63\n",
      "stage iteration: 64\n",
      "stage iteration: 65\n",
      "stage iteration: 66\n",
      "stage iteration: 67\n",
      "stage iteration: 68\n",
      "stage iteration: 69\n",
      "stage iteration: 70\n",
      "stage iteration: 71\n",
      "stage iteration: 72\n",
      "stage iteration: 73\n",
      "stage iteration: 74\n",
      "stage iteration: 75\n",
      "stage iteration: 76\n",
      "stage iteration: 77\n",
      "stage iteration: 78\n",
      "stage iteration: 79\n",
      "stage iteration: 80\n",
      "stage iteration: 81\n",
      "stage iteration: 82\n",
      "stage iteration: 83\n",
      "stage iteration: 84\n",
      "stage iteration: 85\n",
      "stage iteration: 86\n",
      "stage iteration: 87\n",
      "stage iteration: 88\n",
      "stage iteration: 89\n",
      "stage iteration: 90\n",
      "stage iteration: 91\n",
      "stage iteration: 92\n",
      "stage iteration: 93\n",
      "stage iteration: 94\n",
      "stage iteration: 95\n",
      "stage iteration: 96\n",
      "stage iteration: 97\n",
      "eli 67826 [ 88  89  90  91  92  93  94 100 101 242 243 245 247 254 259 260 262 264\n",
      " 271 276 277 279 281 288 293 294 296 298 305 156 157 158 160 161 162 169\n",
      " 208 209 211 213 220 191 192 194 195 196 203 225 226 228 230 237 229 202\n",
      " 193 599 600 602 604 611 616 617 619 621 628 633 634 636 638 645 684 685\n",
      " 687 689 696 650 651 653 655 662 667 668 670 672 679 691 701 702 704 706\n",
      " 713 310 311 313 315 322 378 379 381 383 390 548 549 551 553 560 607 480\n",
      " 481 483 485 492 656 565 566 568 570 577 582 583 585 587 594 207 215 246\n",
      " 283 395 396 398 400 407 412 413 415 417 424 497 498 500 502 509 278 287\n",
      " 531 532 534 536 543 275 292 327 328 330 332 339 463 464 466 468 475 344\n",
      " 345 347 349 356 487 361 362 364 366 373 676 665 718 719 721 723 728 730\n",
      " 674 725 465 499 514 515 517 519 526 533 550 559 503 520 474 516 377 386\n",
      " 394 403 429 430 432 434 441 581 590 564 573 569 586  15 331 348 333 350\n",
      " 411 446 447 449 451 453 458 316 456 749 750 756 759 761 762 758  14  60\n",
      "  61  63  65  66  67  62   0  10  11  12  13  16  17  29  30  31  32  33\n",
      "  34  46  47  48  49  50  70  76  77  82  83  84 105 110 111 114 117 118\n",
      " 122 126 127 128 134 135 139 143 144 145 151 152 172 179 180 184 186 734\n",
      " 740 743 746 747 370 320 404 421 268 319 439 438 422 371 738 178 737 177\n",
      " 142 125 109  75  45  28   9 736 175 141 124 108  74  44  27   8 735 174\n",
      " 140 123 107  73  26 173 106  72  59  43  25   7 760 739  71  58  42  24\n",
      " 450  57  41  23   6 751 742 387 437  56  40  22   5 525  55  39  21   4\n",
      " 727 716  54  38  20   3 359 455  53  37  19   2 482 491 501 365 353  52\n",
      "  36  18   1 470 325 343  51  35 542 537 469 524 444 336 552 428 535 518\n",
      " 448 338 329 224 233 241 212 334 505 410 393 640 623 584 567 427 710 659\n",
      " 643 631 486 440 431 508 527 729 720 708 715 405 399 388 376 433 416 314\n",
      " 547 382 342 357 374 763 754 748 711 699 731 732 660 657 648 677 306 510\n",
      " 694 693 682 733 745 744 741 504 603 538 521 632 624 615 649 641 637 620\n",
      " 666 661 606 703 598 530 522 513 185 176 171 182 391 686 726 722 717 669\n",
      " 652 705 688 644 627 709 700 635 610 692 683 671 654 618 601 675 658 589\n",
      " 588 555 554 572 571 593 576 639 712 622 605 695 678 232 198 496 488 484\n",
      " 479 462 467 454 445 493 419 418 423 402 401 385 392 425 436 523 506 478\n",
      " 221 183 214 223 197 384 368 367 341 414 406 389 380 351 397 408 452 435\n",
      " 461 561 544 168 159 181 372 369 363 360 355 346 340 309 326 218 206 217\n",
      " 201 189 205 200 188 375 358 354 457 476 459 507 490 489 612 511 724 707\n",
      " 697 690 673 680 580 591 663 592 575 574 563 546 557 558 579 529 562 629\n",
      " 541 540 512 495 545 528 642 614 626 597 625 698 609 608 681 664 647 714\n",
      " 170 167 166 164 163 155 154 150 149 147 146 138 137 133 132 129 121 165\n",
      " 153 289 236 227 219 210 324 318 317 337 335 323 300 299 302 291 473 472\n",
      " 420 494 477 460 556 539 630 613 646 764 757 755 753 752  69  81  79  78\n",
      "  64 190 204 187 131 148 321 312 308 307 301 297 284 280 258 270 261 267\n",
      " 263 304 295 303 286 282 274 266 285 442 352 443 596 471 112 130 120 116\n",
      " 113 104 103 136 115 119 102  97  86  85  96  95  99  98  87  68  80 249\n",
      " 248 252 251 240 239 238 235 231 222 234 253 244 257 290 250 265 269 273\n",
      " 216 256 199 272 255 426 409 595 578]\n",
      "time elapsed for elimination ordering:  176.23512148857117 s\n",
      "metis 40259 [298 305 294 293 296 281 276 277 279 288 259 264 262 271 260 245 243 247\n",
      " 254 242  15  13  12  14  43  44  46  48  49  50  42  41  40  35  36  37\n",
      "  39  38  11  16   0  10   9   8   1   2   3   4   5   7   6  45 229 230\n",
      " 226 237 225 228  34  47 236 227 152 151 145 144 139 142 141 140 143 123\n",
      " 128 127 126 125 124 134 135 122 108 107 118 117 106 111 110 105 109  88\n",
      "  89  90  91  92  93  94 101 100  75  74  76  84  77  83  73  72  71  58\n",
      "  59  60  66  67  57  56  54  55  53  65  82  70 174 179 178 186 173 177\n",
      " 175 162 161 160 158 157 156 169  52 168 159 190 203 192 191 195 196 194\n",
      "  61 176 185 207 213 211 220 209 208 212  63  51 232  64  68 206  85 218\n",
      " 199 103  78  80 181  62  79  95 138 150  97 120  99  87 197 164  86  69\n",
      "  81 102  98 115 132 166  96 113 119 130 183 216 189 201 214 149 112 114\n",
      " 116 104 133 121 131 129 147 148 146 136 137 165 155 153 202 193 167 182\n",
      " 198 170 154 172 219 210 163 187 171 215 180 184 204 200 188 221 217 205\n",
      " 238 255 483 485 481 480 492 468 475 466 463 464 447 451 458 446 449 441\n",
      " 430 429 434 432 424 417 415 413 412 400 398 396 395 407 379 381 378 390\n",
      " 383 364 362 361 366 373 322 311 315 313 310  27  28  29  30  31  32  33\n",
      "  26  25  24  17  18  19  20  21  23  22 327 339 332 328 330 425 309 326\n",
      " 408 391 374 357 342 347 344 349 356 345 335 340 353 350 723 730 721 719\n",
      " 718 672 667 670 679 668 553 560 551 548 549 509 502 500 498 497 702 701\n",
      " 713 706 704 705 617 616 619 628 621 602 604 600 599 611 570 577 568 566\n",
      " 565 531 532 543 536 534 519 517 515 514 526 708 615 518 703 624 542 597\n",
      " 521 564 573 537 698 525 516 538 520 711 699 540 603 535 512 533 601 606\n",
      " 529 610 523 524 605 541 609 608 511 528 596 522 620 513 569 530 598 539\n",
      " 607 576 623 618 567 572 627 614 563 571 622 626 625 575 510 574 527 561\n",
      " 595 613 562 612 717 665 728 494 558 545 554 546 673 555 697 715 544 504\n",
      " 556 499 674 550 505 709 496 663 547 714 671 712 493 729 559 503 557 710\n",
      " 707 675 666 700 552 677 678 726 501 664 676 669 508 740 735 736 747 738\n",
      " 684 685 687 689 696 650 653 662 655 651 645 634 633 638 636 583 585 587\n",
      " 582 594 748 757 752 753 755 764 756 759 760 751 754 761 762 758 750 763\n",
      " 749 734 584 680 579 743 746 631 659 724 630 652 732 692 649 640 591 690\n",
      " 691 580 725 737 642 682 590 739 694 641 629 581 733 693 647 578 727 731\n",
      " 722 637 656 593 720 695 648 744 589 588 639 741 745 646 635 592 742 686\n",
      " 688 586 661 683 654 657 644 658 632 716 681 643 660 495 367 371 414 375\n",
      " 422 404 476 421 352 459 455 433 478 469 461 363 423 470 465 331 387 389\n",
      " 358 445 428 410 452 351 490 405 397 385 437 491 479 486 440 506 507 392\n",
      " 489 418 359 474 450 416 488 419 442 386 372 365 439 401 435 341 473 482\n",
      " 431 369 393 477 444 438 467 377 348 394 406 411 420 370 453 427 484 402\n",
      " 426 457 436 409 456 382 443 376 343 471 388 403 380 360 354 368 448 384\n",
      " 462 454 399 487 472 460 316 285 321 308 284 302 320 297 299 250 257 280\n",
      " 244 253 304 295 323 235 256 272 240 283 334 290 303 269 319 292 233 275\n",
      " 239 251 231 300 306 314 312 355 317 223 336 346 266 318 222 261 270 267\n",
      " 268 289 241 248 274 333 282 265 249 273 324 329 291 258 263 252 246 286\n",
      " 234 307 278 287 325 301 337 338 224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eli 0 [   0    1    2 ... 2871 2872  205]\n",
      "time elapsed for elimination ordering:  82.70356321334839 s\n",
      "metis 0 [2872 2871 2862 ...   24   19   11]\n",
      "mm ['bcsstk01.mtx.gz' 'bcsstm13.mtx.gz' 'ck104.mtx.gz' 'mcca.mtx.gz'\n",
      " 'mcfe.mtx.gz' 'zenios.mtx.gz']\n",
      "metadata [(48, 48, 224, 'coordinate', 'real', 'symmetric'), (2003, 2003, 11973, 'coordinate', 'real', 'symmetric'), (104, 104, 992, 'coordinate', 'real', 'general'), (180, 180, 2659, 'coordinate', 'real', 'general'), (765, 765, 24382, 'coordinate', 'real', 'general'), (2873, 2873, 15032, 'coordinate', 'real', 'symmetric')]\n",
      "eli [419, 0, 0, 964, 67826, 0]\n",
      "metis [265, 0, 0, 334, 40259, 0]\n",
      "eli fills/sum(triu) [2.3806818181818183, 0.0, 0.0, 0.5738095238095238, 4.418056279312141, 0.0]\n",
      "metis fills/sum(triu) [1.5056818181818181, 0.0, 0.0, 0.1988095238095238, 2.622394476289734, 0.0]\n",
      "eli_times [0.22521209716796875, 37.22604465484619, 0.08307552337646484, 1.712557315826416, 176.23512148857117, 82.70356321334839]\n",
      "data =  {'mm': array(['bcsstk01.mtx.gz', 'bcsstm13.mtx.gz', 'ck104.mtx.gz',\n",
      "       'mcca.mtx.gz', 'mcfe.mtx.gz', 'zenios.mtx.gz'], dtype='<U15'), 'metadata': [(48, 48, 224, 'coordinate', 'real', 'symmetric'), (2003, 2003, 11973, 'coordinate', 'real', 'symmetric'), (104, 104, 992, 'coordinate', 'real', 'general'), (180, 180, 2659, 'coordinate', 'real', 'general'), (765, 765, 24382, 'coordinate', 'real', 'general'), (2873, 2873, 15032, 'coordinate', 'real', 'symmetric')], 'eli_fills': [419, 0, 0, 964, 67826, 0], 'eli_ratio': [2.3806818181818183, 0.0, 0.0, 0.5738095238095238, 4.418056279312141, 0.0], 'metis_fills': [265, 0, 0, 334, 40259, 0], 'metis_ratio': [1.5056818181818181, 0.0, 0.0, 0.1988095238095238, 2.622394476289734, 0.0], 'eli_times': [0.22521209716796875, 37.22604465484619, 0.08307552337646484, 1.712557315826416, 176.23512148857117, 82.70356321334839]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#check ordering result:\\ne = np.array(e)\\ne_sort = np.sort(e[e != -1])\\nprint(e_sort)\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''testing main for matrix market'''\n",
    "#for all matrices, reload:\n",
    "mypath = \"matrices/mm/\"\n",
    "onlyfiles = np.array([f for f in listdir(mypath) if isfile(join(mypath, f))])\n",
    "#onlyfiles = onlyfiles[[0,2]] #only for testing subslices\n",
    "print(onlyfiles)\n",
    "times = []\n",
    "fills_eli = []\n",
    "fills_metis = []\n",
    "fills_eli_ratio = []\n",
    "fills_metis_ratio = []\n",
    "mat_metadata = []\n",
    "for f in onlyfiles:\n",
    "    G, metadata = load_matrix_market(mypath+f,get_mat_meta=True)\n",
    "    mat_metadata.append(metadata) #matrix metadata\n",
    "    edges = np.sum(G[np.triu_indices(G.shape[0], 1)]) #sum of upper triangular\n",
    "    #initialize: MUST always be in global scope:\n",
    "    G1 = np.copy(G)\n",
    "    G2 = np.copy(G)\n",
    "    e, w, first_zero, last_zero, merge_forest, deleted = initialize(G)\n",
    "\n",
    "    #elimination ordering:\n",
    "    start = time.time()\n",
    "    elimination_ordering(G)\n",
    "    fills, _ = eliminate(G1, e)\n",
    "    fills_eli.append(fills)\n",
    "    print(\"eli\",fills,e)\n",
    "    #print(\"sorted e\", sorted(e))\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    times.append(elapsed)\n",
    "    print(\"time elapsed for elimination ordering: \",elapsed,\"s\")\n",
    "    fills_eli_ratio.append(float(fills/edges))\n",
    "    \n",
    "    #metis:\n",
    "    metis_order = iperm_to_orderlist(\"matrices/ndmetis_iperm/\"+f+\".metisgraph.iperm\")\n",
    "    fills, _ = eliminate(G2, metis_order)\n",
    "    fills_metis.append(fills)\n",
    "    print(\"metis\", fills, metis_order)\n",
    "    fills_metis_ratio.append(float(fills/edges))\n",
    "    #print(\"sorted e\", sorted(metis_order))\n",
    "\n",
    "print(\"mm\",onlyfiles)\n",
    "print(\"metadata\",mat_metadata)\n",
    "print(\"eli\",fills_eli)\n",
    "print(\"metis\",fills_metis)\n",
    "print(\"eli fills/sum(triu)\",fills_eli_ratio)\n",
    "print(\"metis fills/sum(triu)\",fills_metis_ratio)\n",
    "print(\"eli_times\",times)\n",
    "\n",
    "#store results in file\n",
    "data = {\n",
    "    \"mm\": onlyfiles,\n",
    "    \"metadata\": mat_metadata,\n",
    "    \"eli_fills\": fills_eli,\n",
    "    \"eli_ratio\": fills_eli_ratio,\n",
    "    \"metis_fills\": fills_metis,\n",
    "    \"metis_ratio\": fills_metis_ratio,\n",
    "    \"eli_times\": times,\n",
    "}\n",
    "with open('data.p', 'wb') as fp:\n",
    "    pickle.dump(data, fp)    \n",
    "with open('data.p', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "    print(\"data = \",data)\n",
    "\n",
    "'''#check ordering result:\n",
    "e = np.array(e)\n",
    "e_sort = np.sort(e[e != -1])\n",
    "print(e_sort)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179]\n"
     ]
    }
   ],
   "source": [
    "'''above cell must be run first'''\n",
    "#e_sort = e_sort[2:]\n",
    "print(e_sort)\n",
    "#check missing:\n",
    "def printMissingElements(arr, N): \n",
    "    # Initialize diff \n",
    "    diff = arr[0] \n",
    "    for i in range(N): \n",
    "        # Check if diff and arr[i]-i \n",
    "        # both are equal or not \n",
    "        if(arr[i] - i != diff): \n",
    "            # Loop for consecutive \n",
    "            # missing elements \n",
    "            while(diff < arr[i] - i): \n",
    "                print(i + diff, end = \" \") \n",
    "                diff += 1\n",
    "printMissingElements(e_sort, e_sort.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 3, 7, 4], [2, 5, 6]]\n",
      "i, n, m, valency, valencies, e, modified, firstzero, lastzero\n",
      "\n",
      "0 8 2.75 3 [3 3 2 4 3 2 2 3] [-1 -1 -1 -1 -1 -1 -1 -1] [1 1 1 1 1 1 1 1] 8 0 -1\n",
      "neighbours [1 3 7]\n",
      "w,deleted [1 1 1 1 1 1 1 1] []\n",
      "\n",
      "1 8 2.75 3 [3 3 2 4 3 2 2 3] [-1 -1 -1 -1 -1 -1 -1 -1] [0 1 1 1 1 1 1 1] 7 0 -1\n",
      "neighbours [0 3 4]\n",
      "w,deleted [1 1 1 1 1 1 1 1] []\n",
      "\n",
      "2 8 2.75 2 [3 3 2 4 3 2 2 3] [-1 -1 -1 -1 -1 -1 -1 -1] [0 0 1 1 1 1 1 1] 6 0 -1\n",
      "neighbours [5 6]\n",
      "rule 4\n",
      "w,deleted [1 1 1 1 1 1 1 1] [2]\n",
      "\n",
      "3 7 2.5714285714285716 4 [3 3 0 4 3 1 1 3] [ 2 -1 -1 -1 -1 -1 -1 -1] [0 0 0 1 1 1 1 1] 5 1 -1\n",
      "neighbours [0 1 4 7]\n",
      "w,deleted [1 1 1 1 1 1 1 1] [2]\n",
      "\n",
      "4 7 2.5714285714285716 3 [3 3 0 4 3 1 1 3] [ 2 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 1 1 1 1] 4 1 -1\n",
      "neighbours [1 3 7]\n",
      "w,deleted [1 1 1 1 1 1 1 1] [2]\n",
      "\n",
      "5 7 2.5714285714285716 1 [3 3 0 4 3 1 1 3] [ 2 -1 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 1 1 1] 3 1 -1\n",
      "neighbours [6]\n",
      "rule 3\n",
      "w,deleted [1 1 1 1 1 1 1 1] [2 5]\n",
      "\n",
      "6 5 3.2 0 [3 3 0 4 3 0 0 3] [ 2  5 -1 -1 -1 -1 -1 -1] [0 0 0 0 0 0 1 1] 2 2 -1\n",
      "neighbours []\n",
      "rule 3\n",
      "w,deleted [1 1 1 1 1 1 1 1] [2 5 6]\n",
      "\n",
      "7 5 3.2 3 [3 3 0 4 3 0 0 3] [ 2  5  6 -1 -1 -1 -1 -1] [0 0 0 0 0 0 0 1] 1 3 -1\n",
      "neighbours [0 3 4]\n",
      "rule 6\n",
      "[0 3 4] [1 1 1]\n",
      "merged 7 3\n",
      "w,deleted [1 1 1 2 1 1 1 1] [2 5 6 7]\n",
      "\n",
      "\n",
      "0 4 2.5 2 [2 3 0 3 2 0 0 0] [ 2  5  6 -1 -1 -1 -1 -1] [1 0 0 1 1 0 0 0] 3 3 -1\n",
      "neighbours [1 3]\n",
      "rule 4\n",
      "w,deleted [1 1 1 2 1 1 1 1] [0 2 5 6 7]\n",
      "\n",
      "1 3 2.0 2 [0 2 0 2 2 0 0 0] [ 2  5  6  0 -1 -1 -1 -1] [0 1 0 1 1 0 0 0] 3 4 -1\n",
      "neighbours [3 4]\n",
      "rule 1\n",
      "w,deleted [1 1 1 2 1 1 1 1] [0 1 2 5 6 7]\n",
      "\n",
      "already deleted: 2\n",
      "3 2 1.0 1 [0 0 0 1 1 0 0 0] [ 2  5  6  0 -1 -1 -1  1] [0 0 0 1 1 0 0 0] 2 4 -2\n",
      "neighbours [4]\n",
      "S [7]\n",
      "rule 1\n",
      "w,deleted [1 1 1 2 1 1 1 1] [0 1 2 3 5 6 7]\n",
      "\n",
      "4 0 nan 0 [0 0 0 0 0 0 0 0] [ 2  5  6  0 -1  7  3  1] [0 0 0 0 1 0 0 0] 1 4 -4\n",
      "neighbours []\n",
      "rule 3\n",
      "w,deleted [1 1 1 2 1 1 1 1] [0 1 2 3 4 5 6 7]\n",
      "\n",
      "already deleted: 5\n",
      "already deleted: 6\n",
      "already deleted: 7\n",
      "[2 5 6 0 4 7 3 1]\n",
      "from ndmetis [7 1 3 0 2 6 5 4]\n",
      "fills 1\n",
      "from eli normalize [2 5 6 0 4 7 3 1]\n",
      "fills 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:195: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "'''disconnected graph checking, if it is assumed as different \\gamma'''\n",
    "G = np.array([\n",
    "        [0,0,0,1,1,0,0,0],\n",
    "        [0,0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0,0],\n",
    "        [1,0,0,0,1,0,0,0],\n",
    "        [1,0,0,1,0,0,0,0],\n",
    "        [0,0,0,0,0,0,1,1],\n",
    "        [0,0,0,0,0,1,0,1],\n",
    "        [0,0,0,0,0,1,1,0]\n",
    "    ])\n",
    "\n",
    "G = np.array([\n",
    "        [0,1,0,1,0,0,0,1],\n",
    "        [1,0,0,1,1,0,0,0],\n",
    "        [0,0,0,0,0,1,1,0],\n",
    "        [1,1,0,0,1,0,0,1],\n",
    "        [0,1,0,1,0,0,0,1],\n",
    "        [0,0,1,0,0,0,1,0],\n",
    "        [0,0,1,0,0,1,0,0],\n",
    "        [1,0,0,1,1,0,0,0]\n",
    "        \n",
    "    ])\n",
    "G_elim = np.copy(G)\n",
    "visited = np.array([False]*G.shape[0])\n",
    "traverse_count = 0\n",
    "sub_Gs = []\n",
    "for i in range(G.shape[0]):\n",
    "    if not visited[i]:\n",
    "        sub_G = BFS(G,i)\n",
    "        sub_Gs.append(sub_G)\n",
    "        visited[sub_G] = True\n",
    "print(sub_Gs)\n",
    "\n",
    "'''generating subgraphs from a whole matrix graph'''\n",
    "'''Gs = []\n",
    "for i in range(len(sub_Gs)):\n",
    "    #set all indices except i to 0\n",
    "    sliced = []\n",
    "    for j in range(len(sub_Gs)):\n",
    "        if j!=i:\n",
    "            sliced.append(sub_Gs[j])\n",
    "    print(sliced)\n",
    "    sliced = [item for sublist in sliced for item in sublist] #flattened list\n",
    "    print(sliced)\n",
    "    sub_graph = np.copy(G)\n",
    "    sub_graph[sliced] = sub_graph[:,sliced] = 0\n",
    "    Gs.append(sub_graph)\n",
    "print(Gs)\n",
    "for G in Gs:\n",
    "    G_elim = np.copy(G)\n",
    "    e,w,first_zero,last_zero,merge_forest,deleted = initialize(G)\n",
    "    #normalize(G)\n",
    "    separate(G)\n",
    "    print(\"e\",e)\n",
    "    print(eliminate(G_elim,e))\n",
    "    print()\n",
    "'''\n",
    "e,w,first_zero,last_zero,merge_forest,deleted = initialize(G_elim) #always initialize before normalize\n",
    "normalize(G)\n",
    "print(e)\n",
    "elim_order_metis = iperm_to_orderlist(\"disconn_graph.metisgraph.iperm\")\n",
    "print(\"from ndmetis\",elim_order_metis)\n",
    "G_elim2 = np.copy(G_elim)\n",
    "fills, _ = eliminate(G_elim, elim_order_metis) #using metis\n",
    "print(\"fills\",fills)\n",
    "fills, _ = eliminate(G_elim2, e) #using eli\n",
    "print(\"from eli normalize\", e)\n",
    "print(\"fills\",fills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "G = np.array([\n",
    "        [0,1,0,1,0,0,0,1],\n",
    "        [1,0,0,1,1,0,0,0],\n",
    "        [0,0,0,0,0,1,1,0],\n",
    "        [1,1,0,0,1,0,0,1],\n",
    "        [0,1,0,1,0,0,0,1],\n",
    "        [0,0,1,0,0,0,1,0],\n",
    "        [0,0,1,0,0,1,0,0],\n",
    "        [1,0,0,1,1,0,0,0]\n",
    "        \n",
    "    ])\n",
    "upper_tri = G[np.triu_indices(G.shape[0], 1)]\n",
    "#upper_tri = np.triu_indices(G.shape[0], 1)\n",
    "print(np.sum(upper_tri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =  {'mm': array(['bcsstk01.mtx.gz', 'bcsstm13.mtx.gz', 'ck104.mtx.gz',\n",
      "       'mcca.mtx.gz', 'mcfe.mtx.gz', 'zenios.mtx.gz'], dtype='<U15'), 'metadata': [(48, 48, 224, 'coordinate', 'real', 'symmetric'), (2003, 2003, 11973, 'coordinate', 'real', 'symmetric'), (104, 104, 992, 'coordinate', 'real', 'general'), (180, 180, 2659, 'coordinate', 'real', 'general'), (765, 765, 24382, 'coordinate', 'real', 'general'), (2873, 2873, 15032, 'coordinate', 'real', 'symmetric')], 'eli_fills': [419, 0, 0, 964, 67826, 0], 'eli_ratio': [2.3806818181818183, 0.0, 0.0, 0.5738095238095238, 4.418056279312141, 0.0], 'metis_fills': [265, 0, 0, 334, 40259, 0], 'metis_ratio': [1.5056818181818181, 0.0, 0.0, 0.1988095238095238, 2.622394476289734, 0.0], 'eli_times': [0.22521209716796875, 37.22604465484619, 0.08307552337646484, 1.712557315826416, 176.23512148857117, 82.70356321334839]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mm</th>\n",
       "      <th>metadata</th>\n",
       "      <th>eli_fills</th>\n",
       "      <th>eli_ratio</th>\n",
       "      <th>metis_fills</th>\n",
       "      <th>metis_ratio</th>\n",
       "      <th>eli_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bcsstk01.mtx.gz</td>\n",
       "      <td>(48, 48, 224, coordinate, real, symmetric)</td>\n",
       "      <td>419</td>\n",
       "      <td>2.380682</td>\n",
       "      <td>265</td>\n",
       "      <td>1.505682</td>\n",
       "      <td>0.225212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcsstm13.mtx.gz</td>\n",
       "      <td>(2003, 2003, 11973, coordinate, real, symmetric)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.226045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ck104.mtx.gz</td>\n",
       "      <td>(104, 104, 992, coordinate, real, general)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mcca.mtx.gz</td>\n",
       "      <td>(180, 180, 2659, coordinate, real, general)</td>\n",
       "      <td>964</td>\n",
       "      <td>0.573810</td>\n",
       "      <td>334</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>1.712557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mcfe.mtx.gz</td>\n",
       "      <td>(765, 765, 24382, coordinate, real, general)</td>\n",
       "      <td>67826</td>\n",
       "      <td>4.418056</td>\n",
       "      <td>40259</td>\n",
       "      <td>2.622394</td>\n",
       "      <td>176.235121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zenios.mtx.gz</td>\n",
       "      <td>(2873, 2873, 15032, coordinate, real, symmetric)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.703563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mm                                          metadata  \\\n",
       "0  bcsstk01.mtx.gz        (48, 48, 224, coordinate, real, symmetric)   \n",
       "1  bcsstm13.mtx.gz  (2003, 2003, 11973, coordinate, real, symmetric)   \n",
       "2     ck104.mtx.gz        (104, 104, 992, coordinate, real, general)   \n",
       "3      mcca.mtx.gz       (180, 180, 2659, coordinate, real, general)   \n",
       "4      mcfe.mtx.gz      (765, 765, 24382, coordinate, real, general)   \n",
       "5    zenios.mtx.gz  (2873, 2873, 15032, coordinate, real, symmetric)   \n",
       "\n",
       "   eli_fills  eli_ratio  metis_fills  metis_ratio   eli_times  \n",
       "0        419   2.380682          265     1.505682    0.225212  \n",
       "1          0   0.000000            0     0.000000   37.226045  \n",
       "2          0   0.000000            0     0.000000    0.083076  \n",
       "3        964   0.573810          334     0.198810    1.712557  \n",
       "4      67826   4.418056        40259     2.622394  176.235121  \n",
       "5          0   0.000000            0     0.000000   82.703563  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open('data.p', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "    print(\"data = \",data)\n",
    "\n",
    "pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
