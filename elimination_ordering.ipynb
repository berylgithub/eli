{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 1 1 1 0]\n",
      " [1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 1 1 0 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#test array/graph from https://people.sc.fsu.edu/~jburkardt/m_src/rcm/rcm.html\n",
    "graph = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "             ])\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 1 2 0 1 1 0 2 2]\n",
      " [0 2 2 1 1 2 0 0 2 0]\n",
      " [1 2 2 0 1 2 2 2 1 1]\n",
      " [2 1 0 2 0 0 2 1 2 1]\n",
      " [0 1 1 0 0 0 0 2 1 1]\n",
      " [1 2 2 0 0 0 1 0 2 1]\n",
      " [1 0 2 2 0 1 0 2 1 1]\n",
      " [0 0 2 1 2 0 2 0 1 0]\n",
      " [2 2 1 2 1 2 1 1 0 1]\n",
      " [2 0 1 1 1 1 1 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "#to generate rand arr\n",
    "N = 10\n",
    "b = np.random.randint(2,size=(N,N))\n",
    "#b_symm = np.array(np.ceil((b + b.T)/2), dtype=int)\n",
    "#np.fill_diagonal(b_symm, 0)\n",
    "#b_symm\n",
    "print(b+b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from scipy.sparse.csgraph import reverse_cuthill_mckee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 8)\t1\n",
      "  (4, 6)\t1\n",
      "  (4, 7)\t1\n",
      "  (5, 1)\t1\n",
      "  (5, 6)\t1\n",
      "  (6, 1)\t1\n",
      "  (6, 4)\t1\n",
      "  (6, 5)\t1\n",
      "  (7, 0)\t1\n",
      "  (7, 1)\t1\n",
      "  (7, 3)\t1\n",
      "  (7, 4)\t1\n",
      "  (8, 0)\t1\n",
      "  (8, 3)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 3, 6, 5, 7, 8, 1, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_g = csr_matrix(graph)\n",
    "print(c_g)\n",
    "perm = reverse_cuthill_mckee(c_g, True)\n",
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 1 1]\n",
      " [0 1 0 0 1 1 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 1 1 0]\n",
      " [0 0 1 0 0 0 0 1 1]\n",
      " [1 1 0 0 0 0 0 0 0]]\n",
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 4)\t1\n",
      "  (4, 3)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 0)\t1\n",
      "  (5, 3)\t1\n",
      "  (5, 0)\t1\n",
      "  (6, 7)\t1\n",
      "  (6, 6)\t1\n",
      "  (6, 5)\t1\n",
      "  (6, 2)\t1\n",
      "  (7, 8)\t1\n",
      "  (7, 7)\t1\n",
      "  (7, 2)\t1\n",
      "  (8, 1)\t1\n",
      "  (8, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "g = graph[perm]\n",
    "print(g)\n",
    "print(c_g[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t2\n",
      "  (1, 3)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 3)\t3\n"
     ]
    }
   ],
   "source": [
    "graph = [\n",
    "[0, 1 , 2, 0],\n",
    "[0, 0, 0, 1],\n",
    "[2, 0, 0, 3],\n",
    "[0, 0, 0, 0]\n",
    "]\n",
    "graph = csr_matrix(graph)\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [2, 0, 0, 3],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 2, 0]], dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = reverse_cuthill_mckee(graph)\n",
    "print(perm)\n",
    "graph[perm].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 1 1 1 0]\n",
      " [1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 1 1 0 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(graph)\n",
    "graph.shape[0]\n",
    "np.array([-1]*graph.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Elimination Ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Normalize Stage'''\n",
    "'''preliminaries:\n",
    "- node == vertex (\"vertices\" for plural)\n",
    "- nodes' index start at 0\n",
    "- all graphs and trees are represented in matrix farm\n",
    "- valency is the sum of the edges' weights of a node, i.e. the sum of the row in a corresponding index, in numpy:\n",
    "    np.sum(graph[node_idx])\n",
    "'''\n",
    "'''independent functions:'''\n",
    "#clique checker:\n",
    "def clique_check(graph, vertices_idx):\n",
    "    #get subgraph, by slicing indexes:\n",
    "    subgraph = graph[vertices_idx][:,vertices_idx]\n",
    "    n = subgraph.shape[0]\n",
    "    #check for clique from subgraph:\n",
    "    upper_tri = subgraph[np.triu_indices(n, 1)]\n",
    "    return np.sum(upper_tri) == comb(n, 2)\n",
    "\n",
    "#subset checker:\n",
    "def check_subset(graph, neighbours):\n",
    "    bool_subset = False\n",
    "    j_get = None\n",
    "    for j_node in neighbours:\n",
    "        gamma_j = np.where(graph[j_node] == 1)[0]\n",
    "        j_T = np.append(gamma_j, j_node) #j^up_tack = j union gamma(j):= j added to its neighbours\n",
    "        if set(neighbours).issubset(set(j_T)): #gamma(i) \\subset j^up_tack\n",
    "            bool_subset = True\n",
    "            j_get = j_node\n",
    "    return bool_subset, j_get\n",
    "\n",
    "#more accurate way of checking the total nodes within a graph, since the edge is represented \n",
    "#by the value of A[i][j] cell, e.g if i <-> j is connected, it means A[i][j] = A[j][i] 1, otherwise 0, \n",
    "#so the size of the matrix may not correspond to the total number of nodes\n",
    "def get_total_nodes(graph, row_size):\n",
    "    counter = 0\n",
    "    for i in range(row_size):\n",
    "        if np.sum(graph[i]) > 0:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "'''end'''\n",
    "\n",
    "#normalize stage:\n",
    "def normalize(graph):\n",
    "    n = n_init = graph.shape[0] #number of nodes\n",
    "    e = [] #placeholder node vector for elimination ordering\n",
    "    w = np.array([1]*n) #weight vector for merge forest\n",
    "    merge_forest = np.zeros((n,n)) #merge forest for assessment criteria\n",
    "    modified = np.array([1]*n) #modified = 1, otherwise 0\n",
    "    fill_count = 0\n",
    "\n",
    "    #normalize stage\n",
    "    #for now, cyclic ordering assumption: start from the 1st index to last idx, hence for-loop\n",
    "    print(\"i, n, m, valency, valencies, e, modified\")\n",
    "\n",
    "    while np.sum(modified) > 0:\n",
    "        for i in range(n):\n",
    "            if np.sum(modified) == 0:\n",
    "                break\n",
    "            #recalculate all of the values:\n",
    "            #recalculate n by excluding zero vectored rows (disconnected vertices):\n",
    "            n = get_total_nodes(graph, n_init)\n",
    "            valencies = np.array([np.sum(graph[j]) for j in range(n_init)]) #needs to recalculate the valency for each update due to the graph-change\n",
    "            #print(i,n,m,valency,valencies,e,modified)\n",
    "            mean_valency = np.sum(valencies)/n #get mean valency\n",
    "            max_valency = np.max(valencies) #get max valency\n",
    "            valency = np.sum(graph[i]) #get vertex's valency\n",
    "            m = np.min([mean_valency, n**(1/4) + 3])\n",
    "            neighbours = np.where(graph[i] == 1)[0] #get the neighbours of i\n",
    "            print()\n",
    "            print(i,n,m,valency,valencies,e,modified,np.sum(modified))\n",
    "            #check all of the conditions based on the valency\n",
    "            if valency == n-1:\n",
    "                e.append(i) #add to the end\n",
    "                graph[i] = graph[:,i] = 0  #remove from graph by deleting edges\n",
    "                #graph = np.delete(graph, i, 0) #delete from graph -- this should be the proper deletion method, though not sure if it's faster\n",
    "                #graph = np.delete(graph, i, 1)\n",
    "                modified[neighbours] = 1 #set neighbours as modified\n",
    "            elif (valency > n/2) and (valency == max_valency):\n",
    "                e.append(i)\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                modified[neighbours] = 1 #set neighbours as modified\n",
    "            elif valency <= 1:\n",
    "                e.insert(0, i) #place vertex first\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                modified[neighbours] = 1 #set neighbours as modified\n",
    "            elif valency == 2:\n",
    "                e.insert(0, i)\n",
    "                graph[neighbours[0]][neighbours[1]] = graph[neighbours[1]][neighbours[0]] = 1 #make edge between them -- fill the value of the cell with 1\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                modified[neighbours] = 1 #set neighbours as modified\n",
    "            elif (valency <= m) and (clique_check(graph, neighbours)):\n",
    "                e.insert(0, i)\n",
    "                graph[i] = graph[:,i] = 0\n",
    "                modified[neighbours] = 1 #set neighbours as modified\n",
    "            elif (valency <= m):\n",
    "                bool_subset, j_node = check_subset(graph, neighbours) #gamma(i) \\subset j^uptack, j \\in gamma(i)\n",
    "                if bool_subset:\n",
    "                    merge_forest[j_node][i_node] = 1 #merge i into j, add directed edge j->i\n",
    "                    w[j_node] += 1 #increment weight\n",
    "                    graph[i] = graph[:,i] = 0\n",
    "            modified[i] = 0 #set vertex as unmodified\n",
    "    return e, merge_forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Graphs used for initial assesment:\n",
    "graph is:   \n",
    "     5--7--6\n",
    "     |  | /\n",
    "  4--8--2\n",
    "  |  |  |\n",
    "  9--1--3\n",
    "  \n",
    "graph_1 is a bipartite graph (Nauru graph): https://en.wikipedia.org/wiki/Adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 1 1 1 0]\n",
      " [1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 1 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 1 1 0 0 0]\n",
      " [1 1 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''graphs collection for testing'''\n",
    "#test array/graph from https://people.sc.fsu.edu/~jburkardt/m_src/rcm/rcm.html\n",
    "graph = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "            [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "            [0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "            [1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "             ])\n",
    "print(graph)\n",
    "\n",
    "#nauru graph\n",
    "graph_1 = np.zeros((24,24))\n",
    "graph_1[0][1] = graph_1[0][5] = graph_1[0][21] = \\\n",
    "graph_1[1][3] = graph_1[1][15] = \\\n",
    "graph_1[2][3] = graph_1[2][4] = graph_1[2][23] = \\\n",
    "graph_1[3][9] = graph_1[4][5] = graph_1[4][17] = \\\n",
    "graph_1[5][11] = graph_1[6][7] = graph_1[6][11] = graph_1[6][19] = \\\n",
    "graph_1[7][9] = graph_1[7][13] = \\\n",
    "graph_1[8][9] = graph_1[8][10] = graph_1[8][22] = \\\n",
    "graph_1[10][11] = graph_1[10][16] = \\\n",
    "graph_1[12][13] = graph_1[12][17] = graph_1[12][18] = \\\n",
    "graph_1[13][15] = graph_1[14][15] = graph_1[14][16] = graph_1[14][20] = \\\n",
    "graph_1[16][17] = graph_1[18][19] = graph_1[18][23] = \\\n",
    "graph_1[19][21] = graph_1[20][21] = graph_1[20][22] = \\\n",
    "graph_1[22][23] = 1\n",
    "graph_1 += graph_1.T\n",
    "print(np.allclose(graph_1, graph_1.T, rtol=1e-05, atol=1e-08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, n, m, valency, valencies, e, modified\n",
      "\n",
      "0 9 2.6666666666666665 3 [3 4 2 2 2 2 3 4 2] [] [1 1 1 1 1 1 1 1 1] 9\n",
      "\n",
      "1 9 2.6666666666666665 4 [3 4 2 2 2 2 3 4 2] [] [0 1 1 1 1 1 1 1 1] 8\n",
      "\n",
      "2 9 2.6666666666666665 2 [3 4 2 2 2 2 3 4 2] [] [0 0 1 1 1 1 1 1 1] 7\n",
      "\n",
      "3 8 2.75 2 [3 4 0 2 2 2 3 4 2] [2] [1 1 0 1 1 1 1 1 1] 8\n",
      "\n",
      "4 7 2.857142857142857 2 [3 4 0 0 2 2 3 4 2] [3, 2] [1 1 0 0 1 1 1 1 1] 7\n",
      "\n",
      "5 6 3.0 2 [3 4 0 0 0 2 3 4 2] [4, 3, 2] [1 1 0 0 0 1 1 1 1] 6\n",
      "\n",
      "6 5 2.8 2 [3 3 0 0 0 0 2 4 2] [5, 4, 3, 2] [1 1 0 0 0 0 1 1 1] 5\n",
      "\n",
      "7 4 2.5 3 [3 2 0 0 0 0 0 3 2] [6, 5, 4, 3, 2] [1 1 0 0 0 0 0 1 1] 4\n",
      "\n",
      "8 3 1.3333333333333333 1 [2 1 0 0 0 0 0 0 1] [6, 5, 4, 3, 2, 7] [1 1 0 0 0 0 0 0 1] 3\n",
      "\n",
      "0 2 1.0 1 [1 1 0 0 0 0 0 0 0] [8, 6, 5, 4, 3, 2, 7] [1 1 0 0 0 0 0 0 0] 2\n",
      "\n",
      "1 0 nan 0 [0 0 0 0 0 0 0 0 0] [8, 6, 5, 4, 3, 2, 7, 0] [0 1 0 0 0 0 0 0 0] 1\n",
      "([1, 8, 6, 5, 4, 3, 2, 7, 0], array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]]))\n",
      "i, n, m, valency, valencies, e, modified\n",
      "\n",
      "0 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 24\n",
      "\n",
      "1 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 23\n",
      "\n",
      "2 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 22\n",
      "\n",
      "3 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 21\n",
      "\n",
      "4 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 20\n",
      "\n",
      "5 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 19\n",
      "\n",
      "6 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 18\n",
      "\n",
      "7 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 17\n",
      "\n",
      "8 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 16\n",
      "\n",
      "9 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 15\n",
      "\n",
      "10 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 14\n",
      "\n",
      "11 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1] 13\n",
      "\n",
      "12 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1] 12\n",
      "\n",
      "13 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1] 11\n",
      "\n",
      "14 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1] 10\n",
      "\n",
      "15 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1] 9\n",
      "\n",
      "16 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1] 8\n",
      "\n",
      "17 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1] 7\n",
      "\n",
      "18 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1] 6\n",
      "\n",
      "19 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1] 5\n",
      "\n",
      "20 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1] 4\n",
      "\n",
      "21 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1] 3\n",
      "\n",
      "22 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] 2\n",
      "\n",
      "23 24 3.0 3.0 [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] 1\n",
      "([], array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beryl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "'''testing-ground for normalize stage'''\n",
    "print(normalize(graph))\n",
    "print(normalize(graph_1))\n",
    "\n",
    "#comment after testing: it kinda worked, i guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "'''Separate Stage'''\n",
    "d_prime = 0\n",
    "n_init = graph.shape[0] #should be replaced later with actual graph's nodes calculation\n",
    "valencies = np.array([np.sum(graph[i]) for i in range(n_init)])\n",
    "e_sep = np.argmax(valencies) #get the node with max valency\n",
    "s = valencies[e_sep] #get the valency value\n",
    "#need to find a set of M with max distansce from e, which requires BFS or djikstra\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "     4--6--5\n",
    "     |  | /\n",
    "  3--7--1\n",
    "  |  |  |\n",
    "  8--0--2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0 [2 7 8] [2, 7, 8] 3 1\n",
      "2 [0 1] [7, 8, 1] 3 1\n",
      "7 [0 1 3 4] [8, 1, 3, 4] 4 1\n",
      "8 [0 3] [1, 3, 4] 3 1\n",
      "1 [2 5 6 7] [3, 4, 5, 6] 4 1\n",
      "3 [7 8] [4, 5, 6] 3 1\n",
      "4 [6 7] [5, 6] 2 1\n",
      "5 [1 6] [6] 1 1\n",
      "6 [1 4 5] [] 0 2\n"
     ]
    }
   ],
   "source": [
    "n_init = graph.shape[0]\n",
    "print(n_init)\n",
    "'''BFS'''\n",
    "q = []\n",
    "enque = lambda q, x: q.append(x)\n",
    "deque = lambda q: q.pop(0)\n",
    "visited = np.array([0]*n_init)\n",
    "distances = np.array([0]*n_init)\n",
    "source = root = 0\n",
    "visited[source] = 1\n",
    "enque(q, source)\n",
    "depth = 0\n",
    "q_counter = 1 #to keep track how many neighbours enqueued\n",
    "while q:\n",
    "    v = deque(q)\n",
    "    q_counter = q_counter - 1\n",
    "    if q_counter == 0:\n",
    "        depth += 1\n",
    "    neighbours = np.where(graph[v] == 1)[0] #enque all v's neighbours (gamma(v))\n",
    "    for node_i in neighbours:\n",
    "        if (visited[node_i] == 0) and (node_i not in q):\n",
    "            enque(q, node_i)\n",
    "            visited[node_i] = 1\n",
    "            q_counter += 1\n",
    "    print(v, neighbours, q, q_counter, depth)\n",
    "#reverse the path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_init = graph.shape[0]\n",
    "'''dijkstra https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm''' \n",
    "#function to help djikstra algorithm:\n",
    "def get_min_distance_vertex(Q, distances):\n",
    "    min_dist = float(\"inf\")\n",
    "    min_v = None\n",
    "    for v in range(Q.shape[0]):\n",
    "        if (distances[v] < min_dist) and (Q[v] == 1):\n",
    "            min_dist = distances[v]\n",
    "            min_v = v\n",
    "    return min_dist, min_v\n",
    "\n",
    "#start of dijkstra algorithm:\n",
    "def dijkstra_shortest_path(graph, source):\n",
    "    n_init = get_total_nodes(graph, graph.shape[0])\n",
    "    Q = np.array([1]*n_init)\n",
    "    #print(Q)\n",
    "    #source = root = 0\n",
    "    distances = np.array([float(\"inf\")]*n_init) #set distance vector\n",
    "    distances[source] = 0\n",
    "    prev = np.array([None]*n_init)\n",
    "\n",
    "    while np.sum(Q) > 0:\n",
    "        _, u = get_min_distance_vertex(Q, distances) #get the vertex with minimum distance\n",
    "        Q[u] = False #remove u from Q\n",
    "        neighbours = np.where(graph[u] == 1)[0]\n",
    "        #print(u, Q, distances)\n",
    "        for v in neighbours:\n",
    "            if Q[v] == 1:\n",
    "                alt = distances[u] + graph[u][v] #distance is equal to the weight of the edge between u and v\n",
    "                if alt < distances[v]:\n",
    "                    distances[v] = alt\n",
    "                    prev[v] = u\n",
    "                #print(alt)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 0., 1., 2., 2., 1., 1., 1., 3.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''testing ground for dijkstra algo'''\n",
    "dijkstra_shortest_path(graph, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n",
      "[[1 1 0]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "testgraph = np.array([[0,1,1,1],\n",
    "                     [1,0,1,1],\n",
    "                     [1,1,0,1],\n",
    "                     [1,1,1,0]\n",
    "                     ])\n",
    "n = testgraph.shape[0]\n",
    "upper_tri = testgraph[np.triu_indices(n, 1)]\n",
    "np.sum(upper_tri) == comb(n, 2)\n",
    "\n",
    "testgraph = np.array([[0,1,1,0],\n",
    "                     [1,0,1,1],\n",
    "                     [1,1,0,1],\n",
    "                     [0,1,1,0]])\n",
    "slice_idx = [1,2,3]\n",
    "a = testgraph[slice_idx][:,slice_idx] #this is the correct one\n",
    "b = testgraph[:,slice_idx]\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[0 1 1 1]\n",
      " [1 0 1 0]\n",
      " [1 1 0 1]\n",
      " [1 0 1 0]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_subset(graph, neighbours):\n",
    "    bool_subset = False\n",
    "    j_get = None\n",
    "    for j_node in neighbours:\n",
    "        gamma_j = np.where(testgraph[j_node] == 1)[0]\n",
    "        j_T = np.append(gamma_j, j_node) #j^up_tack = j union gamma(j):= j added to its neighbours\n",
    "        if set(neighbours).issubset(set(j_T)): #gamma(i) \\subset j^up_tack\n",
    "            bool_subset = True\n",
    "            j_get = j_node\n",
    "    return bool_subset, j_get\n",
    "\n",
    "testgraph = np.array([[0,1,1,1],\n",
    "                     [1,0,1,0],\n",
    "                     [1,1,0,1],\n",
    "                     [1,0,1,0]\n",
    "                    ])\n",
    "'''\n",
    "testgraph = np.array([[0,1,0,1],\n",
    "                     [1,0,1,0],\n",
    "                     [0,1,0,1],\n",
    "                     [1,0,1,0]\n",
    "                    ])\n",
    "testgraph = np.array([[0,1,1,1,1],\n",
    "                      [1,0,1,0,1],\n",
    "                      [1,1,0,1,0],\n",
    "                      [1,0,1,0,1],\n",
    "                      [1,1,0,1,0]\n",
    "                     ])\n",
    "'''\n",
    "testforest = np.zeros((testgraph.shape))\n",
    "\n",
    "i_node = 0\n",
    "neighbours = np.where(testgraph[i_node] == 1)[0]\n",
    "print(neighbours)\n",
    "bool_subset, j_node = check_subset(testgraph, neighbours)\n",
    "if bool_subset:\n",
    "    testforest[j_node][i_node] = 1\n",
    "\n",
    "print(testgraph)\n",
    "print(testforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
